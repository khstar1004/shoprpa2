#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹œìŠ¤í…œ ìµœì í™” ë° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê°œì„ ëœ RPA ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê³  
ìµœì í™” ì œì•ˆì„ ì œê³µí•©ë‹ˆë‹¤.

Usage:
    python test_system_optimization.py

Features:
    - ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    - ì„¤ì • íŒŒì¼ ê²€ì¦
    - ì„ì‹œ íŒŒì¼ ì •ë¦¬
    - ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
    - ë©”ëª¨ë¦¬ ìµœì í™”
"""

import os
import sys
import logging
import configparser
import time
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
script_dir = Path(__file__).resolve().parent
if str(script_dir) not in sys.path:
    sys.path.insert(0, str(script_dir))

# PythonScript ë””ë ‰í† ë¦¬ ì¶”ê°€
pythonscript_dir = script_dir / 'PythonScript'
if str(pythonscript_dir) not in sys.path:
    sys.path.insert(0, str(pythonscript_dir))

def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    log_format = '%(asctime)s - %(levelname)s - [%(name)s] - %(message)s'
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler('system_optimization_test.log', encoding='utf-8')
        ]
    )

def load_config() -> configparser.ConfigParser:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    config = configparser.ConfigParser()
    config_path = script_dir / 'config.ini'
    
    if config_path.exists():
        config.read(config_path, encoding='utf-8')
        logging.info(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
    else:
        logging.warning(f"âš ï¸ ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}")
        
    return config

def test_hash_functions():
    """í•´ì‹œ í•¨ìˆ˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    try:
        from PythonScript.utils import generate_product_name_hash, extract_product_hash_from_filename
        
        logging.info("ğŸ”§ í•´ì‹œ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # í•´ì‹œ ìƒì„± í…ŒìŠ¤íŠ¸
        test_products = [
            "í…ŒìŠ¤íŠ¸ ìƒí’ˆ 123",
            "Test Product ABC",
            "  ê³µë°±ì´   ë§ì€   ìƒí’ˆ  ",
            "íŠ¹ìˆ˜ë¬¸ì!@#$%^&*()ìƒí’ˆ",
            "í•œê¸€ê³¼Englishí˜¼í•©Product",
            "",  # ë¹ˆ ë¬¸ìì—´
            None  # None ê°’
        ]
        
        results = []
        for product in test_products:
            try:
                hash_value = generate_product_name_hash(product)
                results.append({
                    'input': repr(product),
                    'hash': hash_value,
                    'success': bool(hash_value)
                })
            except Exception as e:
                results.append({
                    'input': repr(product),
                    'error': str(e),
                    'success': False
                })
        
        # ê²°ê³¼ ì¶œë ¥
        success_count = sum(1 for r in results if r['success'])
        logging.info(f"í•´ì‹œ ìƒì„± í…ŒìŠ¤íŠ¸: {success_count}/{len(results)} ì„±ê³µ")
        
        for result in results:
            if result['success']:
                logging.debug(f"  âœ… {result['input']} -> {result['hash']}")
            else:
                logging.debug(f"  âŒ {result['input']} -> ì˜¤ë¥˜: {result.get('error', 'ì‹¤íŒ¨')}")
        
        # í•´ì‹œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        test_filenames = [
            "haereum_1234567890abcdef_12345678.jpg",
            "kogift_abcdef1234567890.png",
            "naver_invalidhash.jpg",
            "1234567890abcdef.jpg",
            "invalid_filename.jpg"
        ]
        
        extract_results = []
        for filename in test_filenames:
            try:
                extracted_hash = extract_product_hash_from_filename(filename)
                extract_results.append({
                    'filename': filename,
                    'extracted': extracted_hash,
                    'success': extracted_hash is not None
                })
            except Exception as e:
                extract_results.append({
                    'filename': filename,
                    'error': str(e),
                    'success': False
                })
        
        extract_success = sum(1 for r in extract_results if r['success'])
        logging.info(f"í•´ì‹œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸: {extract_success}/{len(extract_results)} ì„±ê³µ")
        
        return {
            'hash_generation': results,
            'hash_extraction': extract_results,
            'overall_success': success_count > 0 and extract_success > 0
        }
        
    except ImportError as e:
        logging.error(f"âŒ í•´ì‹œ í•¨ìˆ˜ import ì‹¤íŒ¨: {e}")
        return {'error': str(e), 'overall_success': False}
    except Exception as e:
        logging.error(f"âŒ í•´ì‹œ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return {'error': str(e), 'overall_success': False}

def test_performance_monitoring(config):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸"""
    try:
        from PythonScript.utils import (
            monitor_system_performance, 
            optimize_memory_usage,
            validate_configuration,
            cleanup_temp_files,
            benchmark_system_performance
        )
        
        logging.info("ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # 1. ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        perf_data = monitor_system_performance(config)
        if 'error' not in perf_data:
            logging.info(f"ì‹œìŠ¤í…œ ìƒíƒœ: {perf_data['emoji']} {perf_data['status']} "
                        f"(ì ìˆ˜: {perf_data['performance_score']})")
            
            metrics = perf_data['system_metrics']
            logging.info(f"  ë©”ëª¨ë¦¬: {metrics['memory_percent']:.1f}% "
                        f"(ê°€ìš©: {metrics['memory_available_gb']}GB)")
            logging.info(f"  CPU: {metrics['cpu_percent']:.1f}% "
                        f"({metrics['cpu_count']}ì½”ì–´)")
            logging.info(f"  ë””ìŠ¤í¬: {metrics['disk_percent']:.1f}% "
                        f"(ê°€ìš©: {metrics['disk_free_gb']:.1f}GB)")
            logging.info(f"  GPU: {metrics['gpu_info']}")
            
            if perf_data['recommendations']:
                logging.info("ê¶Œì¥ì‚¬í•­:")
                for rec in perf_data['recommendations']:
                    logging.info(f"  {rec}")
        else:
            logging.error(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {perf_data['error']}")
        
        # 2. ë©”ëª¨ë¦¬ ìµœì í™”
        mem_result = optimize_memory_usage()
        if mem_result:
            logging.info(f"ë©”ëª¨ë¦¬ ìµœì í™”: {mem_result['objects_collected']}ê°œ ê°ì²´ ì •ë¦¬")
        
        # 3. ì„¤ì • ê²€ì¦
        suggestions = validate_configuration(config)
        logging.info(f"ì„¤ì • ê²€ì¦ ì™„ë£Œ: {len(suggestions)}ê°œ í•­ëª©")
        for suggestion in suggestions[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
            logging.info(f"  {suggestion}")
        
        # 4. ì„ì‹œ íŒŒì¼ ì •ë¦¬
        cleanup_result = cleanup_temp_files(config, max_age_days=1)
        if 'error' not in cleanup_result:
            if cleanup_result['deleted_files_count'] > 0:
                logging.info(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬: {cleanup_result['deleted_files_count']}ê°œ íŒŒì¼ "
                           f"({cleanup_result['deleted_size_mb']}MB) ì‚­ì œ")
            else:
                logging.info("ì •ë¦¬í•  ì„ì‹œ íŒŒì¼ ì—†ìŒ")
        else:
            logging.warning(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì˜¤ë¥˜: {cleanup_result['error']}")
        
        # 5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
        benchmark_result = benchmark_system_performance(config)
        if 'error' not in benchmark_result:
            logging.info(f"ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬: {benchmark_result['grade']} "
                        f"(ì ìˆ˜: {benchmark_result['overall_score']})")
            
            tests = benchmark_result['tests']
            if 'hash_generation' in tests:
                hash_test = tests['hash_generation']
                logging.info(f"  í•´ì‹œ ìƒì„±: {hash_test['time_seconds']}ì´ˆ "
                           f"({hash_test['ops_per_second']} ops/sec)")
        else:
            logging.error(f"ë²¤ì¹˜ë§ˆí¬ ì˜¤ë¥˜: {benchmark_result['error']}")
        
        return {
            'performance_monitoring': perf_data,
            'memory_optimization': mem_result,
            'config_validation': suggestions,
            'cleanup': cleanup_result,
            'benchmark': benchmark_result,
            'overall_success': True
        }
        
    except ImportError as e:
        logging.error(f"âŒ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜ import ì‹¤íŒ¨: {e}")
        return {'error': str(e), 'overall_success': False}
    except Exception as e:
        logging.error(f"âŒ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return {'error': str(e), 'overall_success': False}

def test_image_integration():
    """ì´ë¯¸ì§€ í†µí•© ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    try:
        from PythonScript.image_integration import (
            get_system_status_summary,
            print_system_status
        )
        
        logging.info("ğŸ–¼ï¸ ì´ë¯¸ì§€ í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½
        status = get_system_status_summary()
        if 'error' not in status:
            logging.info(f"ì´ë¯¸ì§€ ë§¤ì¹­ ì‹œìŠ¤í…œ: {status['matching_system']['version']}")
            logging.info(f"í•´ì‹œ ì•Œê³ ë¦¬ì¦˜: {status['matching_system']['hash_algorithm']}")
            logging.info(f"ê³ ê¸‰ ë§¤ì²˜ ì‚¬ìš© ê°€ëŠ¥: {status['matching_system']['enhanced_matcher_available']}")
            
            improvements = status.get('improvements', [])
            logging.info(f"ì£¼ìš” ê°œì„ ì‚¬í•­: {len(improvements)}ê°œ")
            for improvement in improvements:
                logging.debug(f"  {improvement}")
        else:
            logging.error(f"ì´ë¯¸ì§€ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {status['error']}")
        
        return {
            'system_status': status,
            'overall_success': 'error' not in status
        }
        
    except ImportError as e:
        logging.error(f"âŒ ì´ë¯¸ì§€ í†µí•© í•¨ìˆ˜ import ì‹¤íŒ¨: {e}")
        return {'error': str(e), 'overall_success': False}
    except Exception as e:
        logging.error(f"âŒ ì´ë¯¸ì§€ í†µí•© í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return {'error': str(e), 'overall_success': False}

def run_comprehensive_test():
    """ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logging.info("ğŸš€ ì‹œìŠ¤í…œ ìµœì í™” ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logging.info("=" * 60)
    
    start_time = time.time()
    config = load_config()
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìˆ˜ì§‘
    test_results = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'tests': {}
    }
    
    # 1. í•´ì‹œ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
    logging.info("\n1ï¸âƒ£ í•´ì‹œ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")
    hash_result = test_hash_functions()
    test_results['tests']['hash_functions'] = hash_result
    
    # 2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸
    logging.info("\n2ï¸âƒ£ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸")
    perf_result = test_performance_monitoring(config)
    test_results['tests']['performance_monitoring'] = perf_result
    
    # 3. ì´ë¯¸ì§€ í†µí•© í…ŒìŠ¤íŠ¸
    logging.info("\n3ï¸âƒ£ ì´ë¯¸ì§€ í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    image_result = test_image_integration()
    test_results['tests']['image_integration'] = image_result
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    total_time = time.time() - start_time
    success_count = sum(1 for test in test_results['tests'].values() 
                       if test.get('overall_success', False))
    total_tests = len(test_results['tests'])
    
    test_results['summary'] = {
        'total_time_seconds': round(total_time, 2),
        'successful_tests': success_count,
        'total_tests': total_tests,
        'success_rate': round((success_count / total_tests * 100), 1) if total_tests > 0 else 0
    }
    
    logging.info("\n" + "=" * 60)
    logging.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ì™„ë£Œ ìš”ì•½")
    logging.info("=" * 60)
    logging.info(f"ì‹¤í–‰ ì‹œê°„: {test_results['summary']['total_time_seconds']}ì´ˆ")
    logging.info(f"ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {success_count}/{total_tests}")
    logging.info(f"ì„±ê³µë¥ : {test_results['summary']['success_rate']}%")
    
    # ê°œë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼
    for test_name, result in test_results['tests'].items():
        status = "âœ… ì„±ê³µ" if result.get('overall_success', False) else "âŒ ì‹¤íŒ¨"
        logging.info(f"  {test_name}: {status}")
        if 'error' in result:
            logging.info(f"    ì˜¤ë¥˜: {result['error']}")
    
    # ì „ì²´ í‰ê°€
    if test_results['summary']['success_rate'] >= 80:
        logging.info("ğŸ‰ ì „ì²´ í‰ê°€: ìš°ìˆ˜ - ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
    elif test_results['summary']['success_rate'] >= 60:
        logging.info("ğŸ‘ ì „ì²´ í‰ê°€: ì–‘í˜¸ - ëŒ€ë¶€ë¶„ì˜ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        logging.info("âš ï¸ ì „ì²´ í‰ê°€: ê°œì„  í•„ìš” - ì¼ë¶€ ê¸°ëŠ¥ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
    
    return test_results

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    setup_logging()
    
    try:
        logging.info("ì‹œìŠ¤í…œ ìµœì í™” ë° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸")
        logging.info(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        results = run_comprehensive_test()
        
        # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        import json
        result_file = script_dir / f"test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        logging.info(f"\nğŸ“„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {result_file}")
        
        return results['summary']['success_rate'] >= 80
        
    except Exception as e:
        logging.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        import traceback
        logging.debug(traceback.format_exc())
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 