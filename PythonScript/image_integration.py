import os
import logging
import pandas as pd
from pathlib import Path
import configparser
from typing import Dict, Any, Optional, List, Tuple, Set, Union
from openpyxl import Workbook
from openpyxl.drawing.image import Image
from openpyxl.utils import get_column_letter
import shutil
import sys
import re
import hashlib
from datetime import datetime
import glob
import time
import json
import numpy as np
import tqdm
import traceback
import openpyxl
import PIL

# Add the parent directory to sys.path to allow imports from PythonScript
current_dir = Path(__file__).resolve().parent
parent_dir = current_dir.parent
if str(parent_dir) not in sys.path:
    sys.path.insert(0, str(parent_dir))

# Import common utilities first
try:
    from .utils import generate_product_name_hash, extract_product_hash_from_filename
    from .tokenize_product_names import tokenize_product_name, extract_meaningful_keywords
    logging.info("âœ… ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ì„±ê³µì ìœ¼ë¡œ importí–ˆìŠµë‹ˆë‹¤.")
except ImportError:
    try:
        from utils import generate_product_name_hash, extract_product_hash_from_filename
        from tokenize_product_names import tokenize_product_name, extract_meaningful_keywords
        logging.info("âœ… ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ì§ì ‘ importí–ˆìŠµë‹ˆë‹¤.")
    except ImportError as e:
        logging.error(f"âŒ ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ import ì‹¤íŒ¨: {e}")
        # Fallback implementations
        def generate_product_name_hash(product_name: str) -> str:
            """Fallback hash generation"""
            try:
                normalized = ''.join(product_name.split()).lower()
                return hashlib.md5(normalized.encode('utf-8')).hexdigest()[:16]
            except Exception:
                return ""
        
        def extract_product_hash_from_filename(filename: str) -> Optional[str]:
            """Fallback hash extraction"""
            try:
                name = os.path.splitext(os.path.basename(filename))[0]
                parts = name.split('_')
                if len(parts) >= 2 and len(parts[1]) == 16:
                    return parts[1].lower()
                return None
            except Exception:
                return None

# Initialize logger
logger = logging.getLogger(__name__)

# Import enhanced image matcher with improved error handling
try:
    from .enhanced_image_matcher import EnhancedImageMatcher, check_gpu_status
    ENHANCED_MATCHER_AVAILABLE = True
    logging.info("âœ… ê³ ê¸‰ ì´ë¯¸ì§€ ë§¤ì²˜ë¥¼ ì„±ê³µì ìœ¼ë¡œ importí–ˆìŠµë‹ˆë‹¤.")
except ImportError:
    try:
        from enhanced_image_matcher import EnhancedImageMatcher, check_gpu_status
        ENHANCED_MATCHER_AVAILABLE = True
        logging.info("âœ… ê³ ê¸‰ ì´ë¯¸ì§€ ë§¤ì²˜ë¥¼ ì§ì ‘ importí–ˆìŠµë‹ˆë‹¤.")
    except ImportError:
        ENHANCED_MATCHER_AVAILABLE = False
        logging.warning("âš ï¸ ê³ ê¸‰ ì´ë¯¸ì§€ ë§¤ì²˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë§¤ì¹­ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

def prepare_image_metadata(image_dir: Path, prefix: str, prefer_original: bool = True, prefer_jpg: bool = True) -> Dict[str, Dict]:
    """
    ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        prefix: ì´ë¯¸ì§€ ì†ŒìŠ¤ êµ¬ë¶„ìš© ì ‘ë‘ì‚¬ (ì˜ˆ: 'haereum', 'kogift', 'naver')
        prefer_original: _nobgê°€ ì•„ë‹Œ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ìš°ì„ ì‹œí• ì§€ ì—¬ë¶€
        prefer_jpg: PNGë³´ë‹¤ JPG íŒŒì¼ì„ ìš°ì„ ì‹œí• ì§€ ì—¬ë¶€
        
    Returns:
        ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í‚¤ë¡œ, ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
    """
    image_info = {}
    
    # Normalize path to use forward slashes
    abs_image_dir = os.path.abspath(str(image_dir)).replace('\\', '/')
    logging.info(f"Preparing image metadata from directory: {abs_image_dir} (prefix: {prefix}, prefer_original: {prefer_original}, prefer_jpg: {prefer_jpg})")
    
    # Handle case where directory doesn't exist
    if not os.path.exists(abs_image_dir):
        logging.warning(f"Image directory does not exist: {abs_image_dir}")
        return {}
    
    # First look for image files in the directory
    all_image_files = []
    valid_extensions = ('.jpg', '.jpeg', '.png', '.gif')
    
    try:
        # Get all image files with normalized paths
        for root, _, files in os.walk(abs_image_dir):
            root = root.replace('\\', '/')  # Normalize path
            for file in files:
                if file.lower().endswith(valid_extensions):
                    full_path = os.path.join(root, file).replace('\\', '/')
                    all_image_files.append(full_path)
        
        logging.info(f"Found {len(all_image_files)} total images in {abs_image_dir}")
        
        # Group images by base name (without _nobg suffix)
        image_groups = {}
        
        for img_path in all_image_files:
            filename = os.path.basename(img_path)
            file_root, file_ext = os.path.splitext(filename)
            
            # Handle _nobg suffix
            base_name = file_root
            is_nobg = False
            if file_root.endswith('_nobg'):
                base_name = file_root[:-5]  # Remove _nobg suffix
                is_nobg = True
                
            # Group by base name
            if base_name not in image_groups:
                image_groups[base_name] = {'original_jpg': None, 'original_png': None, 'nobg_png': None, 'nobg_jpg': None}
                
            # Store the path based on type and extension
            if is_nobg:
                if file_ext.lower() in ['.jpg', '.jpeg']:
                    image_groups[base_name]['nobg_jpg'] = img_path
                else:
                    image_groups[base_name]['nobg_png'] = img_path
            else:
                if file_ext.lower() in ['.jpg', '.jpeg']:
                    image_groups[base_name]['original_jpg'] = img_path
                else:
                    image_groups[base_name]['original_png'] = img_path
        
        # Process each group and prioritize files according to preferences
        for base_name, paths in image_groups.items():
            try:
                # Select the best path based on preferences
                img_path = None
                
                # Priority order based on preferences:
                if prefer_original and prefer_jpg:
                    # 1. Original JPG
                    # 2. Original PNG
                    # 3. Nobg JPG
                    # 4. Nobg PNG
                    if paths['original_jpg']:
                        img_path = paths['original_jpg']
                    elif paths['original_png']:
                        img_path = paths['original_png']
                    elif paths['nobg_jpg']:
                        img_path = paths['nobg_jpg']
                    elif paths['nobg_png']:
                        img_path = paths['nobg_png']
                elif prefer_original and not prefer_jpg:
                    # 1. Original PNG
                    # 2. Original JPG
                    # 3. Nobg PNG
                    # 4. Nobg JPG
                    if paths['original_png']:
                        img_path = paths['original_png']
                    elif paths['original_jpg']:
                        img_path = paths['original_jpg']
                    elif paths['nobg_png']:
                        img_path = paths['nobg_png']
                    elif paths['nobg_jpg']:
                        img_path = paths['nobg_jpg']
                elif not prefer_original and prefer_jpg:
                    # 1. Nobg JPG
                    # 2. Original JPG
                    # 3. Nobg PNG
                    # 4. Original PNG
                    if paths['nobg_jpg']:
                        img_path = paths['nobg_jpg']
                    elif paths['original_jpg']:
                        img_path = paths['original_jpg']
                    elif paths['nobg_png']:
                        img_path = paths['nobg_png']
                    elif paths['original_png']:
                        img_path = paths['original_png']
                else:
                    # not prefer_original and not prefer_jpg
                    # 1. Nobg PNG
                    # 2. Original PNG
                    # 3. Nobg JPG
                    # 4. Original JPG
                    if paths['nobg_png']:
                        img_path = paths['nobg_png']
                    elif paths['original_png']:
                        img_path = paths['original_png']
                    elif paths['nobg_jpg']:
                        img_path = paths['nobg_jpg']
                    elif paths['original_jpg']:
                        img_path = paths['original_jpg']
                
                # Skip if no image found
                if not img_path:
                    continue
                
                # Always store all available paths for reference
                original_jpg_path = paths['original_jpg']
                original_png_path = paths['original_png']
                nobg_png_path = paths['nobg_png']
                nobg_jpg_path = paths['nobg_jpg']
                
                # Extract metadata
                filename = os.path.basename(img_path)
                file_root, file_ext = os.path.splitext(filename)
                
                # Extract product hash from filename
                product_hash = extract_product_hash_from_filename(filename)
                if product_hash:
                    logging.debug(f"Extracted hash '{product_hash}' from filename '{filename}'")
                
                # Create metadata dictionary
                metadata = {
                    'path': img_path,
                    'filename': filename,
                    'extension': file_ext.lower(),
                    'is_original': not file_root.endswith('_nobg'),
                    'original_jpg_path': original_jpg_path,
                    'original_png_path': original_png_path,
                    'nobg_jpg_path': nobg_jpg_path,
                    'nobg_png_path': nobg_png_path,
                    'source': prefix.rstrip('_'),
                    'base_name': base_name,
                    'product_hash': product_hash  # Add product hash to metadata
                }
                
                # Store metadata in image_info dictionary
                image_info[img_path] = metadata
                
                # Debug some sample entries
                if len(image_info) <= 2 or len(image_info) % 50 == 0:
                    logging.debug(f"Image metadata sample: {img_path} -> {metadata}")
            
            except Exception as e:
                import traceback
                stack_trace = traceback.format_exc()
                logging.error(f"Error processing image file {base_name}: {e}")
                logging.debug(f"Exception traceback: {stack_trace}")
                continue  # Skip this image but continue processing others
        
        # Log summary
        logging.info(f"Processed {len(image_info)} {prefix} images")
        
        # Additional debug information
        if image_info:
            logging.debug(f"First 3 image keys in {prefix} image_info: {list(image_info.keys())[:3]}")
        else:
            logging.warning(f"No images were successfully processed for {prefix}")
        
        return image_info
        
    except Exception as e:
        import traceback
        stack_trace = traceback.format_exc()
        logging.error(f"Error preparing image metadata from {abs_image_dir}: {e}")
        logging.debug(f"Exception traceback: {stack_trace}")
        return {}

def calculate_similarity(product_tokens: List[str], image_tokens: List[str]) -> float:
    """
    ìƒí’ˆëª…ê³¼ ì´ë¯¸ì§€ ì´ë¦„ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    ì£¼ì˜: ì´ í•¨ìˆ˜ëŠ” ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•´ì„œë§Œ ìœ ì§€ë©ë‹ˆë‹¤.
    ì‹¤ì œ ë§¤ì¹­ì—ì„œëŠ” í•´ì‹œ ê¸°ë°˜ ì •í™•í•œ ë§¤ì¹­ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Args:
        product_tokens: ìƒí’ˆëª…ì—ì„œ ì¶”ì¶œí•œ í† í° ëª©ë¡
        image_tokens: ì´ë¯¸ì§€ ì´ë¦„ì—ì„œ ì¶”ì¶œí•œ í† í° ëª©ë¡
        
    Returns:
        ìœ ì‚¬ë„ ì ìˆ˜ (0.0 ~ 1.0) - í•´ì‹œ ë§¤ì¹­ì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
    """
    # í•´ì‹œ ë§¤ì¹­ ì‹œìŠ¤í…œì—ì„œëŠ” ì´ í•¨ìˆ˜ê°€ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤
    # ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•´ì„œë§Œ ìœ ì§€
    
    if not product_tokens or not image_tokens:
        return 0.0
    
    # í† í° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° (ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
    common_tokens = set(product_tokens) & set(image_tokens)
    
    # ë” ì •í™•í•œ ìœ ì‚¬ë„ ê³„ì‚° - í† í°ì˜ ê¸¸ì´ì™€ ìˆ˜ë¥¼ ê³ ë ¤
    total_tokens = len(set(product_tokens) | set(image_tokens))
    if total_tokens == 0:
        return 0.0
        
    similarity = len(common_tokens) / total_tokens
    
    # ë” ê¸´ í† í°ì´ ë§¤ì¹­ë˜ë©´ ê°€ì¤‘ì¹˜ ë¶€ì—¬
    weight = 1.0
    for token in common_tokens:
        if len(token) >= 4:  # 4ê¸€ì ì´ìƒ í† í°ì— ê°€ì¤‘ì¹˜
            weight += 0.1
    
    return min(similarity * weight, 1.0) # Ensure score doesn't exceed 1.0

def find_best_image_matches(product_names: List[str], 
                           haereum_images: Dict[str, Dict], 
                           kogift_images: Dict[str, Dict], 
                           naver_images: Dict[str, Dict],
                           similarity_threshold: float = 0.8,  # ë” ì—„ê²©í•œ ì„ê³„ê°’ìœ¼ë¡œ ë³€ê²½
                           config: Optional[configparser.ConfigParser] = None,
                           df: Optional[pd.DataFrame] = None) -> List[Tuple[Optional[str], Optional[str], Optional[str]]]:
    """
    ê°œì„ ëœ 2ë‹¨ê³„ ìƒí’ˆ ì´ë¯¸ì§€ ë§¤ì¹­ ì‹œìŠ¤í…œ
    
    ë‹¨ê³„ 1: í•´ì‹œ ê¸°ë°˜ ì •í™•í•œ ë§¤ì¹­ (MD5 í•´ì‹œ ë¹„êµ)
    ë‹¨ê³„ 2: ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ì¦ (0.8 ì„ê³„ê°’)
    
    Args:
        product_names: ë§¤ì¹­í•  ìƒí’ˆëª… ë¦¬ìŠ¤íŠ¸
        haereum_images: í•´ì˜¤ë¦„ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        kogift_images: ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        naver_images: ë„¤ì´ë²„ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        similarity_threshold: ì´ë¯¸ì§€ ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸: 0.8)
        config: ì„¤ì • ê°ì²´
        df: ìƒí’ˆ ì •ë³´ DataFrame
        
    Returns:
        ê° ìƒí’ˆì— ëŒ€í•œ (haereum_match, kogift_match, naver_match) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    """
    
    logging.info("ğŸš€ ê°œì„ ëœ 2ë‹¨ê³„ ë§¤ì¹­ ì‹œìŠ¤í…œ ì‹œì‘")
    logging.info(f"ğŸ“Š ì…ë ¥ ë°ì´í„°: ìƒí’ˆ {len(product_names)}ê°œ, í•´ì˜¤ë¦„ {len(haereum_images)}ê°œ, "
                f"ê³ ë ¤ê¸°í”„íŠ¸ {len(kogift_images)}ê°œ, ë„¤ì´ë²„ {len(naver_images)}ê°œ")
    
    # ì„¤ì •ê°’ ë¡œë“œ
    if config:
        try:
            similarity_threshold = config.getfloat('ImageMatching', 'similarity_threshold', fallback=similarity_threshold)
        except (configparser.Error, ValueError):
            logging.warning(f"ì„¤ì •ì—ì„œ similarity_thresholdë¥¼ ì½ì„ ìˆ˜ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©: {similarity_threshold}")
    
    # ê³ ê¸‰ ì´ë¯¸ì§€ ë§¤ì²˜ ì´ˆê¸°í™”
    enhanced_matcher = None
    try:
        from enhanced_image_matcher import EnhancedImageMatcher
        enhanced_matcher = EnhancedImageMatcher(config)
        use_gpu = getattr(enhanced_matcher, 'use_gpu', False)
        logging.info(f"âœ… ê³ ê¸‰ ì´ë¯¸ì§€ ë§¤ì²˜ ì´ˆê¸°í™” ì™„ë£Œ (GPU: {use_gpu})")
    except Exception as e:
        logging.error(f"âŒ ê³ ê¸‰ ì´ë¯¸ì§€ ë§¤ì²˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        logging.warning("ê¸°ë³¸ ë§¤ì¹­ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # ë§¤ì¹­ ê²°ê³¼ ë° ì‚¬ìš©ëœ ì´ë¯¸ì§€ ì¶”ì 
    best_matches = []
    used_haereum = set()
    used_kogift = set()
    used_naver = set()
    
    # í†µê³„ ë³€ìˆ˜
    hash_matches = 0
    image_verified = 0
    no_matches = 0
    
    # ê° ìƒí’ˆì— ëŒ€í•´ ë§¤ì¹­ ìˆ˜í–‰
    for idx, product_name in enumerate(product_names):
        if (idx + 1) % 10 == 0:
            logging.info(f"ì§„í–‰ ìƒí™©: {idx + 1}/{len(product_names)} ì²˜ë¦¬ ì¤‘...")
        
        logging.debug(f"\nğŸ“¦ ìƒí’ˆ '{product_name}' ë§¤ì¹­ ì‹œì‘")
        
        # === ë‹¨ê³„ 1: í•´ì‹œ ê¸°ë°˜ ì •í™•í•œ ë§¤ì¹­ ===
        product_hash = generate_product_name_hash(product_name)
        hash_candidates = {
            'haereum': [],
            'kogift': [],
            'naver': []
        }
        
        if product_hash:
            logging.debug(f"ğŸ”‘ ìƒì„±ëœ í•´ì‹œ: {product_hash}")
            
            # ê° ì†ŒìŠ¤ì—ì„œ í•´ì‹œ ë§¤ì¹­ í›„ë³´ ì°¾ê¸°
            for h_path, h_info in haereum_images.items():
                if h_path not in used_haereum:
                    img_hash = h_info.get('product_hash')
                    if img_hash and img_hash == product_hash:
                        hash_candidates['haereum'].append((h_path, h_info))
            
            for k_path, k_info in kogift_images.items():
                if k_path not in used_kogift:
                    img_hash = k_info.get('product_hash')
                    if img_hash and img_hash == product_hash:
                        hash_candidates['kogift'].append((k_path, k_info))
            
            for n_path, n_info in naver_images.items():
                if n_path not in used_naver:
                    img_hash = n_info.get('product_hash')
                    if img_hash and img_hash == product_hash:
                        hash_candidates['naver'].append((n_path, n_info))
            
            total_hash_candidates = (len(hash_candidates['haereum']) + 
                                   len(hash_candidates['kogift']) + 
                                   len(hash_candidates['naver']))
            
            logging.debug(f"ğŸ¯ í•´ì‹œ ë§¤ì¹­ í›„ë³´: í•´ì˜¤ë¦„ {len(hash_candidates['haereum'])}ê°œ, "
                         f"ê³ ë ¤ê¸°í”„íŠ¸ {len(hash_candidates['kogift'])}ê°œ, ë„¤ì´ë²„ {len(hash_candidates['naver'])}ê°œ")
            
            # === ë‹¨ê³„ 2: ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ì¦ (í•´ì‹œ ë§¤ì¹­ í›„ë³´ê°€ ìˆì„ ë•Œë§Œ) ===
            final_matches = {'haereum': None, 'kogift': None, 'naver': None}
            
            if total_hash_candidates > 0:
                # enhanced_matcherê°€ ì—†ì–´ë„ í•´ì‹œ ë§¤ì¹­ì€ ìˆ˜í–‰
                if enhanced_matcher:
                    logging.debug(f"ğŸ” ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ì¦ ì‹œì‘ (ì„ê³„ê°’: {similarity_threshold})")
                else:
                    logging.debug(f"ğŸ” Enhanced matcher ì—†ìŒ - í•´ì‹œ ë§¤ì¹­ë§Œìœ¼ë¡œ ì§„í–‰")
                
                # ê¸°ì¤€ ì´ë¯¸ì§€ ì„ íƒ (í•´ì˜¤ë¦„ > ê³ ë ¤ê¸°í”„íŠ¸ > ë„¤ì´ë²„ ìˆœ)
                reference_path = None
                reference_source = None
                
                if hash_candidates['haereum']:
                    ref_path, ref_info = hash_candidates['haereum'][0]
                    reference_path = ref_info.get('path', ref_path)
                    reference_source = 'haereum'
                elif hash_candidates['kogift']:
                    ref_path, ref_info = hash_candidates['kogift'][0]
                    reference_path = ref_info.get('path', ref_path)
                    reference_source = 'kogift'
                elif hash_candidates['naver']:
                    ref_path, ref_info = hash_candidates['naver'][0]
                    reference_path = ref_info.get('path', ref_path)
                    reference_source = 'naver'
                
                # Enhanced matcherê°€ ì—†ìœ¼ë©´ í•´ì‹œ ë§¤ì¹­ë§Œìœ¼ë¡œ í™•ì •
                if not enhanced_matcher:
                    # í•´ì‹œê°€ ì¼ì¹˜í•˜ëŠ” ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë§¤ì¹­ìœ¼ë¡œ í™•ì •
                    for source in ['haereum', 'kogift', 'naver']:
                        if hash_candidates[source]:
                            path, info = hash_candidates[source][0]
                            final_matches[source] = (path, info)
                            if source == 'haereum':
                                used_haereum.add(path)
                            elif source == 'kogift':
                                used_kogift.add(path)
                            elif source == 'naver':
                                used_naver.add(path)
                            logging.info(f"âœ… {source} í•´ì‹œ ë§¤ì¹­ ì„±ê³µ: {os.path.basename(path)}")
                
                elif reference_path and os.path.exists(reference_path):
                    logging.debug(f"ğŸ“ ê¸°ì¤€ ì´ë¯¸ì§€: {reference_source} - {os.path.basename(reference_path)}")
                    
                    # ê¸°ì¤€ ì´ë¯¸ì§€ì˜ ë§¤ì¹­ í™•ì •
                    if reference_source == 'haereum':
                        final_matches['haereum'] = hash_candidates['haereum'][0]
                        used_haereum.add(hash_candidates['haereum'][0][0])
                    elif reference_source == 'kogift':
                        final_matches['kogift'] = hash_candidates['kogift'][0]
                        used_kogift.add(hash_candidates['kogift'][0][0])
                    elif reference_source == 'naver':
                        final_matches['naver'] = hash_candidates['naver'][0]
                        used_naver.add(hash_candidates['naver'][0][0])
                    
                    # ë‹¤ë¥¸ ì†ŒìŠ¤ë“¤ê³¼ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ì¦
                    for source, candidates in hash_candidates.items():
                        if source == reference_source or not candidates:
                            continue
                        
                        for candidate_path, candidate_info in candidates:
                            candidate_img_path = candidate_info.get('path', candidate_path)
                            
                            if os.path.exists(candidate_img_path):
                                try:
                                    similarity = enhanced_matcher.calculate_similarity(reference_path, candidate_img_path)
                                    logging.debug(f"ğŸ” ìœ ì‚¬ë„ ê²€ì‚¬: {reference_source} vs {source} = {similarity:.3f}")
                                    
                                    if similarity >= similarity_threshold:
                                        final_matches[source] = (candidate_path, candidate_info)
                                        if source == 'haereum':
                                            used_haereum.add(candidate_path)
                                        elif source == 'kogift':
                                            used_kogift.add(candidate_path)
                                        elif source == 'naver':
                                            used_naver.add(candidate_path)
                                        
                                        logging.info(f"âœ… {source} ë§¤ì¹­ ì„±ê³µ: {os.path.basename(candidate_path)} (ìœ ì‚¬ë„: {similarity:.3f})")
                                        break
                                    else:
                                        logging.debug(f"âŒ ìœ ì‚¬ë„ ë¶€ì¡±: {source} {similarity:.3f} < {similarity_threshold}")
                                        
                                except Exception as e:
                                    logging.error(f"ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
                            else:
                                logging.warning(f"ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {candidate_img_path}")
                
                # ë§¤ì¹­ ê²°ê³¼ ì •ë¦¬
                if any(final_matches.values()):
                    hash_matches += 1
                    if total_hash_candidates > 1:  # 2ê°œ ì´ìƒ ì†ŒìŠ¤ì—ì„œ í•´ì‹œ ë§¤ì¹­ëœ ê²½ìš°
                        image_verified += 1
                    
                    logging.info(f"ğŸ‰ '{product_name}' í•´ì‹œ+ì´ë¯¸ì§€ ë§¤ì¹­ ì™„ë£Œ")
                    
                    # ê²°ê³¼ ì¶”ê°€
                    best_matches.append((
                        (final_matches['haereum'][0], 0.95) if final_matches['haereum'] else None,
                        (final_matches['kogift'][0], 0.95) if final_matches['kogift'] else None,
                        (final_matches['naver'][0], 0.95) if final_matches['naver'] else None
                    ))
                    continue
        
        # === í•´ì‹œ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ë§¤ì¹­ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬ ===
        logging.debug(f"âŒ '{product_name}' í•´ì‹œ ë§¤ì¹­ ì‹¤íŒ¨ - ë§¤ì¹­ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬")
        no_matches += 1
        
        best_matches.append((None, None, None))
    
    # ìµœì¢… í†µê³„ ì¶œë ¥
    success_rate = (hash_matches / len(product_names) * 100) if product_names else 0
    verification_rate = (image_verified / hash_matches * 100) if hash_matches > 0 else 0
    
    logging.info("\nğŸ“ˆ === ë§¤ì¹­ ì™„ë£Œ í†µê³„ ===")
    logging.info(f"âœ… í•´ì‹œ ë§¤ì¹­ ì„±ê³µ: {hash_matches}/{len(product_names)} ({success_rate:.1f}%)")
    logging.info(f"ğŸ” ì´ë¯¸ì§€ ê²€ì¦ ì™„ë£Œ: {image_verified}/{hash_matches} ({verification_rate:.1f}%)")
    logging.info(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨: {no_matches}/{len(product_names)} ({100-success_rate:.1f}%)")
    logging.info(f"ğŸƒâ€â™‚ï¸ ì‚¬ìš©ëœ ì´ë¯¸ì§€: í•´ì˜¤ë¦„ {len(used_haereum)}, ê³ ë ¤ê¸°í”„íŠ¸ {len(used_kogift)}, ë„¤ì´ë²„ {len(used_naver)}")
    
    # ì„±ëŠ¥ í†µê³„
    if len(product_names) > 0:
        efficiency_score = hash_matches / len(product_names)
        if efficiency_score >= 0.8:
            logging.info("ğŸ† ë§¤ì¹­ íš¨ìœ¨ì„±: ìš°ìˆ˜ (80% ì´ìƒ)")
        elif efficiency_score >= 0.6:
            logging.info("ğŸ‘ ë§¤ì¹­ íš¨ìœ¨ì„±: ì–‘í˜¸ (60% ì´ìƒ)")
        else:
            logging.info("âš ï¸ ë§¤ì¹­ íš¨ìœ¨ì„±: ê°œì„  í•„ìš” (60% ë¯¸ë§Œ)")
    
    return best_matches

def find_best_match_for_product(product_tokens: List[str], 
                               image_info: Dict[str, Dict], 
                               used_images: Set[str] = None,
                               similarity_threshold: float = 0.45,  # ì„ê³„ê°’ ìƒí–¥ ì¡°ì • (0.3ì—ì„œ 0.45ìœ¼ë¡œ)
                               source_name_for_log: str = "UnknownSource",
                               config: Optional[configparser.ConfigParser] = None) -> Optional[Tuple[str, float]]:
    """
    Find the best matching image for a product based on hash matching only.
    No text similarity calculation - only hash-based matching.
    
    Args:
        product_tokens: Tokens of the product name (used for hash generation)
        image_info: Dictionary of image metadata
        used_images: Set of already used image paths
        similarity_threshold: Not used in hash matching, kept for compatibility
        source_name_for_log: Source name for logging
        config: Configuration object for retrieving settings
        
    Returns:
        Tuple of (best_match_path, hash_match_score) or None if no hash match found
    """
    if not product_tokens:
        return None
        
    if used_images is None:
        used_images = set()
    
    # Generate product hash from tokens
    product_name_str = ' '.join(product_tokens)
    product_hash = generate_product_name_hash(product_name_str)
    
    if not product_hash:
        logging.debug(f"[{source_name_for_log}] Could not generate hash for product: {product_name_str}")
        return None
    
    logging.debug(f"[{source_name_for_log}] Looking for hash match: {product_hash}")
    
    # Look for exact hash matches only
    for img_path, img_data in image_info.items():
        # Skip if already used
        if img_path in used_images:
            continue
            
        # Get hash from image metadata
        img_hash = img_data.get('product_hash')
        if not img_hash:
            continue
            
        # Check for exact hash match
        if img_hash == product_hash:
            img_name = img_data.get('original_name', os.path.basename(img_path))
            logging.info(f"{source_name_for_log}: Hash match found for '{product_name_str}': '{img_name}' (hash: {product_hash})")
            return img_path, 0.95  # High score for hash match
    
    logging.debug(f"[{source_name_for_log}] No hash match found for: {product_name_str} (hash: {product_hash})")
    return None

def find_best_match_with_enhanced_matcher(
    source_img_path: str, 
    target_images: Dict[str, Dict], 
    used_images: Set[str] = None,
    enhanced_matcher: Any = None
) -> Optional[Tuple[str, float]]:
    """
    Enhanced image matching with stricter thresholds for higher quality matches.
    """
    if not enhanced_matcher:
        logging.warning("Enhanced image matcher not available. Falling back to text-based matching.")
        return None
        
    if used_images is None:
        used_images = set()
        
    best_match = None
    best_score = 0
    
    # Using higher thresholds for stricter matching
    high_confidence_threshold = 0.30   # 0.15ì—ì„œ 0.30ìœ¼ë¡œ ìƒí–¥
    min_confidence_threshold = 0.15    # 0.00001ì—ì„œ 0.15ë¡œ ëŒ€í­ ìƒí–¥
    
    gpu_info = "GPU enabled" if getattr(enhanced_matcher, 'use_gpu', False) else "CPU mode"
    logging.info(f"Running enhanced matching on {len(target_images)} target images against source: {os.path.basename(source_img_path)} ({gpu_info})")
    
    # Check if source image exists
    if not os.path.exists(source_img_path):
        logging.error(f"Source image doesn't exist: {source_img_path}")
        return None
    
    # Track timing for performance analysis
    start_time = time.time()
    matches_checked = 0
    high_conf_matches = 0
    
    # Debug: Log some target image paths for verification
    sample_keys = list(target_images.keys())[:3] if len(target_images) > 3 else list(target_images.keys())
    for key in sample_keys:
        logging.info(f"Sample target image key: {key}")
        if isinstance(target_images[key], dict):
            img_path = target_images[key].get('path', key)
            logging.info(f"  - Path from dict: {img_path}")
            if os.path.exists(img_path):
                logging.info(f"  - This path exists on disk")
            else:
                logging.info(f"  - This path does NOT exist on disk")
        else:
            logging.info(f"  - Value is not a dict: {type(target_images[key])}")
    
    for image_path, image_info in target_images.items():
        # Skip if already used
        if image_path in used_images:
            continue
        
        # Determine the actual path to use
        actual_path = image_path
        if isinstance(image_info, dict):
            if 'path' in image_info:
                actual_path = image_info['path']
            
            # Try to use nobg version if available (for potentially better matching)
            if enhanced_matcher.USE_BACKGROUND_REMOVAL and isinstance(image_info, dict):
                # Check nobg paths
                nobg_png = image_info.get('nobg_png_path')
                nobg_jpg = image_info.get('nobg_jpg_path')
                
                # Prefer PNG version for nobg (usually better quality)
                if nobg_png and os.path.exists(nobg_png):
                    logging.debug(f"Using background-removed PNG version for matching: {os.path.basename(nobg_png)}")
                    actual_path = nobg_png
                elif nobg_jpg and os.path.exists(nobg_jpg):
                    logging.debug(f"Using background-removed JPG version for matching: {os.path.basename(nobg_jpg)}")
                    actual_path = nobg_jpg
            
        # Check if image exists
        if not os.path.exists(actual_path):
            logging.warning(f"Target image doesn't exist: {actual_path} (key: {image_path})")
            continue
        
        try:
            logging.debug(f"Comparing source {os.path.basename(source_img_path)} with target {os.path.basename(actual_path)}")
            # Call the calculate_similarity method directly instead of is_match to get raw similarity
            similarity = enhanced_matcher.calculate_similarity(source_img_path, actual_path)
            
            # Log similarity score for debugging
            logging.debug(f"Raw similarity score: {similarity:.4f} for {os.path.basename(actual_path)}")
            
            matches_checked += 1
            
            if similarity > high_confidence_threshold:
                high_conf_matches += 1
                logging.info(f"High confidence match: {os.path.basename(actual_path)} = {similarity:.4f}")
                
            if similarity > best_score:
                best_score = similarity
                best_match = image_path  # Keep the original key, not the resolved path
                logging.info(f"New best match: {os.path.basename(actual_path)} with score {similarity:.4f}")
                
                # Early exit for very high confidence matches to save processing time
                if similarity > 0.75:
                    logging.info(f"Found very high confidence match ({similarity:.4f}), early exit")
                    break
                    
        except Exception as e:
            logging.error(f"Error comparing images: {e}")
            
    # Compute time spent
    elapsed = time.time() - start_time
    
    # Don't return matches below the absolute minimum threshold
    if best_match and best_score < min_confidence_threshold:
        logging.info(f"Best match score ({best_score:.4f}) below min threshold ({min_confidence_threshold})")
        return None
        
    # Log summary of matching results
    if best_match:
        if isinstance(target_images[best_match], dict) and 'path' in target_images[best_match]:
            best_path = target_images[best_match]['path']
        else:
            best_path = best_match
        logging.info(f"Best image match: {os.path.basename(best_path)} ({best_score:.4f}) [checked {matches_checked} images in {elapsed:.2f}s, {high_conf_matches} high confidence]")
    else:
        logging.info(f"No image match found after checking {matches_checked} images in {elapsed:.2f}s")
    
    return (best_match, best_score) if best_match else None

def verify_image_matches(best_matches, product_names, haereum_images, kogift_images, naver_images):
    """
    ì´ë¯¸ì§€ ë§¤ì¹­ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    í”„ë¡œë•íŠ¸ ì´ë¦„ê³¼ íŒŒì¼ ì´ë¦„ ê°„ì˜ ê³µí†µ í† í°ì„ í™•ì¸í•˜ì—¬ ë§¤ì¹­ í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        best_matches: find_best_image_matches í•¨ìˆ˜ì˜ ê²°ê³¼
        product_names: ìƒí’ˆëª… ëª©ë¡
        haereum_images: í•´ì˜¤ë¦„ ì´ë¯¸ì§€ ì •ë³´
        kogift_images: ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€ ì •ë³´
        naver_images: ë„¤ì´ë²„ ì´ë¯¸ì§€ ì •ë³´
        
    Returns:
        ê²€ì¦ëœ ë§¤ì¹­ ê²°ê³¼
    """
    verified_matches = []
    
    # ID ê¸°ë°˜ ë§¤ì¹­ì— ì‚¬ìš©ë˜ëŠ” ì •ê·œ í‘œí˜„ì‹
    id_pattern = re.compile(r'_([a-f0-9]{10})(?:\.jpg|\.png|_nobg\.png)?$')
    
    for idx, (product_name, match_set) in enumerate(zip(product_names, best_matches)):
        # Handle cases where match_set may not have exactly 3 elements
        # or if elements within are not as expected (e.g. None instead of (path, score) tuple)
        haereum_data, kogift_data, naver_data = None, None, None # Initialize with None

        if match_set and len(match_set) == 3:
            haereum_data, kogift_data, naver_data = match_set
        else:
            logging.warning(f"Invalid match_set for product '{product_name}': {match_set}. Using None values for all sources.")
            # haereum_data, kogift_data, naver_data remain None as initialized

        product_tokens = set(tokenize_product_name(product_name))
        
        # ë§¤ì¹­ í’ˆì§ˆ ê¸°ë¡
        match_quality = {
            'haereum': {'score': 0, 'match': haereum_data, 'id': None}, # Store data tuple directly
            'kogift': {'score': 0, 'match': kogift_data, 'id': None},  # Store data tuple directly
            'naver': {'score': 0, 'match': naver_data, 'id': None}    # Store data tuple directly
        }
        
        # í•´ì˜¤ë¦„ ë§¤ì¹­ ê²€ì¦
        if haereum_data and isinstance(haereum_data, tuple) and len(haereum_data) == 2:
            haereum_path, haereum_score = haereum_data
            match_quality['haereum']['score'] = haereum_score # Use the propagated score
            
            if haereum_path and haereum_path in haereum_images:
                haereum_filename = os.path.basename(haereum_path)
                haereum_id = None
                id_match = id_pattern.search(haereum_filename)
                if id_match:
                    haereum_id = id_match.group(1)
                
                haereum_tokens = set(tokenize_product_name(haereum_images[haereum_path].get('clean_name', 
                                                        haereum_images[haereum_path].get('name_for_matching', ''))))
                common_tokens = product_tokens & haereum_tokens
                token_ratio = len(common_tokens) / max(len(product_tokens), 1)
                
                # Refine score, but start with the propagated score
                match_quality['haereum']['score'] = haereum_score * (1 + token_ratio) 
                match_quality['haereum']['id'] = haereum_id
            else:
                logging.warning(f"Haereum path '{haereum_path}' not found in haereum_images or path is None.")
                match_quality['haereum']['match'] = None # Invalidate if path issue
                match_quality['haereum']['score'] = 0
        elif haereum_data: # Was not None, but not a (path, score) tuple
             logging.warning(f"Unexpected format for haereum_data: {haereum_data}. Clearing Haereum match.")
             match_quality['haereum']['match'] = None
             match_quality['haereum']['score'] = 0
        
        # ê³ ë ¤ê¸°í”„íŠ¸ ë§¤ì¹­ ê²€ì¦
        if kogift_data and isinstance(kogift_data, tuple) and len(kogift_data) == 2:
            kogift_path, kogift_score = kogift_data
            match_quality['kogift']['score'] = kogift_score # Use the propagated score

            if kogift_path and kogift_path in kogift_images:
                kogift_filename = os.path.basename(kogift_path)
                kogift_id = None
                id_match = id_pattern.search(kogift_filename)
                if id_match:
                    kogift_id = id_match.group(1)
                
                haereum_id_for_comparison = match_quality['haereum'].get('id')
                if haereum_id_for_comparison and haereum_id_for_comparison == kogift_id:
                    match_quality['kogift']['score'] = max(kogift_score, 0.8) * 1.5
                else:
                    kogift_tokens = set(tokenize_product_name(kogift_images[kogift_path].get('clean_name',
                                                         kogift_images[kogift_path].get('name_for_matching', ''))))
                    common_tokens = product_tokens & kogift_tokens
                    token_ratio = len(common_tokens) / max(len(product_tokens), 1)
                    match_quality['kogift']['score'] = kogift_score * (1 + token_ratio)
                match_quality['kogift']['id'] = kogift_id
            else:
                logging.warning(f"Kogift path '{kogift_path}' not found in kogift_images or path is None.")
                match_quality['kogift']['match'] = None # Invalidate if path issue
                match_quality['kogift']['score'] = 0
        elif kogift_data: # Was not None, but not a (path, score) tuple
             logging.warning(f"Unexpected format for kogift_data: {kogift_data}. Clearing Kogift match.")
             match_quality['kogift']['match'] = None
             match_quality['kogift']['score'] = 0

        # ë„¤ì´ë²„ ë§¤ì¹­ ê²€ì¦
        if naver_data and isinstance(naver_data, tuple) and len(naver_data) == 2:
            naver_path, naver_score = naver_data
            match_quality['naver']['score'] = naver_score # Use the propagated score

            if naver_path and naver_path in naver_images:
                naver_filename = os.path.basename(naver_path)
                naver_id = None
                id_match = id_pattern.search(naver_filename)
                if id_match:
                    naver_id = id_match.group(1)
                
                haereum_id_for_comparison = match_quality['haereum'].get('id')
                if haereum_id_for_comparison and haereum_id_for_comparison == naver_id:
                    match_quality['naver']['score'] = max(naver_score, 0.8) * 1.5
                else:
                    naver_tokens = set(tokenize_product_name(naver_images[naver_path].get('clean_name',
                                                        naver_images[naver_path].get('name_for_matching', ''))))
                    common_tokens = product_tokens & naver_tokens
                    token_ratio = len(common_tokens) / max(len(product_tokens), 1)
                    # Refine score, but start with the propagated score
                    match_quality['naver']['score'] = naver_score * (1 + token_ratio) 
                match_quality['naver']['id'] = naver_id
            else:
                logging.warning(f"Naver path '{naver_path}' not found in naver_images or path is None.")
                match_quality['naver']['match'] = None # Invalidate if path issue
                match_quality['naver']['score'] = 0
        elif naver_data: # Was not None, but not a (path, score) tuple
             logging.warning(f"Unexpected format for naver_data: {naver_data}. Clearing Naver match.")
             match_quality['naver']['match'] = None
             match_quality['naver']['score'] = 0
        
        # ê²€ì¦ ê²°ê³¼ë¥¼ ë¡œê·¸ë¡œ ì¶œë ¥
        logging.debug(f"Product: '{product_name}' - Verification scores: Haereum={match_quality['haereum']['score']:.2f}, Kogift={match_quality['kogift']['score']:.2f}, Naver={match_quality['naver']['score']:.2f}")
        
        # ìµœì¢… ê²€ì¦ëœ ë§¤ì¹­ ê²°ê³¼ ì¶”ê°€
        verified_matches.append((
            match_quality['haereum']['match'],
            match_quality['kogift']['match'],
            match_quality['naver']['match']
        ))
    
    return verified_matches

def integrate_images(df: pd.DataFrame, config: configparser.ConfigParser) -> pd.DataFrame:
    """
    ì„¸ ê°€ì§€ ì´ë¯¸ì§€ ì†ŒìŠ¤(í•´ì˜¤ë¦„, ê³ ë ¤ê¸°í”„íŠ¸, ë„¤ì´ë²„)ì˜ ì´ë¯¸ì§€ë¥¼ DataFrameì— í†µí•©í•©ë‹ˆë‹¤.
    ìƒí’ˆë³„ë¡œ ì¼ê´€ëœ ì´ë¯¸ì§€ ë§¤ì¹­ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    
    Note: Haereum images (ë³¸ì‚¬ ì´ë¯¸ì§€) are ALWAYS included, regardless of matching scores.
    
    Args:
        df: ì²˜ë¦¬í•  DataFrame (data_processing.pyì˜ format_product_data_for_outputì„ ê±°ì¹œ ìƒíƒœì—¬ì•¼ í•¨)
        config: ì„¤ì • íŒŒì¼
        
    Returns:
        ì´ë¯¸ì§€ê°€ í†µí•©ëœ DataFrame
    """
    try:
        logging.info("í†µí•©: ì´ë¯¸ì§€ í†µí•© í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")
        result_df = df.copy() # dfëŠ” ì´ë¯¸ format_product_data_for_outputì„ ê±°ì³ ì´ë¯¸ì§€ ì»¬ëŸ¼ì— dictê°€ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒ

        # These column names are expected to be in the input df, potentially holding original scraped URLs
        # if they were not already incorporated into the image dictionaries by data_processing.py
        scraped_haereum_url_col_input_df = 'ë³¸ì‚¬ì´ë¯¸ì§€URL' 
        scraped_kogift_url_col_input_df = 'ê³ ë ¤ê¸°í”„íŠ¸ì´ë¯¸ì§€URL' 
        scraped_naver_url_col_input_df = 'ë„¤ì´ë²„ì´ë¯¸ì§€URL'
        
        # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        main_img_dir = Path(config.get('Paths', 'image_main_dir', fallback='C:\\\\RPA\\\\Image\\\\Main'))
        haereum_dir = main_img_dir / 'Haereum'
        kogift_dir = main_img_dir / 'Kogift'
        naver_dir = main_img_dir / 'Naver'
        
        # ë””ë ‰í† ë¦¬ ì¡´ì¬ ì²´í¬
        if not haereum_dir.exists():
            logging.warning(f"í•´ì˜¤ë¦„ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {haereum_dir}")
        if not kogift_dir.exists():
            logging.warning(f"ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {kogift_dir}")
        if not naver_dir.exists():
            logging.warning(f"ë„¤ì´ë²„ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {naver_dir}")
        
        # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¤€ë¹„
        haereum_images = prepare_image_metadata(haereum_dir, 'haereum_', prefer_original=True, prefer_jpg=True)
        kogift_images = prepare_image_metadata(kogift_dir, 'kogift_', prefer_original=True, prefer_jpg=True)
        naver_images = prepare_image_metadata(naver_dir, 'naver_', prefer_original=True, prefer_jpg=True)
        
        # í•„ìš”í•œ ì—´ ì¶”ê°€
        if 'ë³¸ì‚¬ ì´ë¯¸ì§€' not in result_df.columns:
            result_df['ë³¸ì‚¬ ì´ë¯¸ì§€'] = None
        if 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€' not in result_df.columns:
            result_df['ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'] = None
        if 'ë„¤ì´ë²„ ì´ë¯¸ì§€' not in result_df.columns:
            result_df['ë„¤ì´ë²„ ì´ë¯¸ì§€'] = None
        
        # Ensure target columns for image data exist before processing
        # These are the final column names used for output (e.g., in Excel)
        target_cols = ['ë³¸ì‚¬ ì´ë¯¸ì§€', 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€', 'ë„¤ì´ë²„ ì´ë¯¸ì§€']
        for col in target_cols:
            if col not in result_df.columns:
                # Initialize with a suitable default, e.g., None or '-'
                # Using None initially might be better if subsequent logic checks for None
                result_df[col] = None 
                logging.debug(f"Added missing target image column: {col}")

        # ìƒí’ˆ ëª©ë¡ ì¶”ì¶œ
        product_names = result_df['ìƒí’ˆëª…'].tolist()
        
        # ì œí’ˆ ìˆ˜ì™€ ì´ë¯¸ì§€ ìˆ˜ ë¡œê¹…
        logging.info(f"ì œí’ˆ ìˆ˜: {len(product_names)}ê°œ")
        logging.info(f"í•´ì˜¤ë¦„ ì´ë¯¸ì§€: {len(haereum_images)}ê°œ")
        logging.info(f"ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€: {len(kogift_images)}ê°œ")
        logging.info(f"ë„¤ì´ë²„ ì´ë¯¸ì§€: {len(naver_images)}ê°œ")
        
        # ìƒí’ˆëª… ìƒ˜í”Œ ë¡œê¹…
        if product_names:
            sample_products = product_names[:3] if len(product_names) > 3 else product_names
            logging.debug(f"ì œí’ˆ ìƒ˜í”Œ: {sample_products}")
        
        # Retrieve similarity threshold from config with higher quality defaults
        # 1) Primary key: Matching.text_threshold (higher quality standard)
        # 2) Secondary key: Matching.image_threshold 
        # 3) Tertiary key: ImageMatching.minimum_match_confidence
        # 4) Fallback: 0.4 (high quality default)
        
        # Get thresholds in priority order
        text_threshold = None
        image_threshold = None
        min_match_confidence = None
        
        try:
            if config.has_option('Matching', 'text_threshold'):
                text_threshold = config.getfloat('Matching', 'text_threshold')
                logging.debug(f"Read text_threshold: {text_threshold}")
        except (configparser.Error, ValueError) as e:
            logging.warning(f"Could not read [Matching] text_threshold: {e}")
            
        try:
            if config.has_option('Matching', 'image_threshold'):
                image_threshold = config.getfloat('Matching', 'image_threshold')
                logging.debug(f"Read image_threshold: {image_threshold}")
        except (configparser.Error, ValueError) as e:
            logging.warning(f"Could not read [Matching] image_threshold: {e}")

        try:
            if config.has_option('ImageMatching', 'minimum_match_confidence'):
                min_match_confidence = config.getfloat('ImageMatching', 'minimum_match_confidence')
                logging.debug(f"Read minimum_match_confidence: {min_match_confidence}")
        except (configparser.Error, ValueError) as e:
            logging.warning(f"Could not read [ImageMatching] minimum_match_confidence: {e}")

        # Use the first available threshold, with higher defaults
        if text_threshold is not None:
            similarity_threshold = text_threshold
        elif image_threshold is not None:
            similarity_threshold = image_threshold
        elif min_match_confidence is not None:
            similarity_threshold = min_match_confidence
        else:
            similarity_threshold = 0.4  # Higher quality default
            logging.warning(f"Using higher quality default similarity_threshold of {similarity_threshold} as specific values not found or invalid in config.")
        
        # Set the initial matching threshold
        initial_matching_threshold = similarity_threshold # Use the general similarity_threshold from config or default
        
        logging.info(f"ì´ë¯¸ì§€ ë§¤ì¹­ ìœ ì‚¬ë„ ì„ê³„ê°’ (for find_best_image_matches): {initial_matching_threshold}")
        
        # Initialize enhanced matcher for image similarity calculations
        enhanced_matcher = None
        try:
            if ENHANCED_MATCHER_AVAILABLE:
                enhanced_matcher = EnhancedImageMatcher(config)
                use_gpu = getattr(enhanced_matcher, 'use_gpu', False)
                logging.info(f"âœ… ê³ ê¸‰ ì´ë¯¸ì§€ ë§¤ì²˜ ì´ˆê¸°í™” ì™„ë£Œ (GPU: {use_gpu})")
        except Exception as e:
            logging.warning(f"âš ï¸ ê³ ê¸‰ ì´ë¯¸ì§€ ë§¤ì²˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logging.warning("ê¸°ë³¸ ë§¤ì¹­ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # ìµœì  ë§¤ì¹˜ ì°¾ê¸° (ì¼ê´€ì„± ë³´ì¥)
        best_matches = find_best_image_matches(
            product_names,
            haereum_images,
            kogift_images,
            naver_images,
            similarity_threshold=initial_matching_threshold,  # Use lower threshold for initial matching
            config=config,
            df=result_df  # Pass DataFrame for product code matching
        )
        
        # ë§¤ì¹­ ê²°ê³¼ ê²€ì¦
        logging.info(f"ì´ë¯¸ì§€ ë§¤ì¹­ ê²€ì¦ ì¤‘...")
        verified_matches = verify_image_matches(
            best_matches,
            product_names,
            haereum_images,
            kogift_images,
            naver_images
        )
        
        # ê²°ê³¼ë¥¼ DataFrameì— ì ìš©
        # Map for matching web URL columns with their correct names in the dataframe
        assumed_url_cols = {
            'haereum': 'ë³¸ì‚¬ìƒí’ˆë§í¬',      # Changed from 'ë³¸ì‚¬ë§í¬'
            'kogift': 'ê³ ë ¤ê¸°í”„íŠ¸ ìƒí’ˆë§í¬', # Changed from 'ê³ ë ¤ ë§í¬'
            'naver': 'ë„¤ì´ë²„ ì‡¼í•‘ ë§í¬'     # Changed from 'ë„¤ì´ë²„ ë§í¬'
        }

        # Pre-compute Koreagift product info existence for all rows
        # Will be used to determine if image should be assigned
        kogift_product_info_exists = []
        for idx in range(len(result_df)):
            if idx >= len(result_df):
                kogift_product_info_exists.append(False)
                continue
                
            row_data = result_df.iloc[idx]
            has_kogift_info = False
            
            # Check for Koreagift link
            kogift_link_col = 'ê³ ë ¤ê¸°í”„íŠ¸ ìƒí’ˆë§í¬'
            if kogift_link_col in row_data and row_data[kogift_link_col]:
                if isinstance(row_data[kogift_link_col], str) and row_data[kogift_link_col].strip() not in ['', '-', 'None', None]:
                    has_kogift_info = True
            
            # Check for Koreagift price
            if not has_kogift_info:
                kogift_price_col = 'íŒë§¤ê°€(Ví¬í•¨)(2)'
                if kogift_price_col in row_data and pd.notna(row_data[kogift_price_col]) and row_data[kogift_price_col] not in [0, '-', '', None]:
                    has_kogift_info = True
                    
            # Check for alternative price column
            if not has_kogift_info:
                alt_kogift_price_col = 'íŒë§¤ë‹¨ê°€(Ví¬í•¨)(2)'
                if alt_kogift_price_col in row_data and pd.notna(row_data[alt_kogift_price_col]) and row_data[alt_kogift_price_col] not in [0, '-', '', None]:
                    has_kogift_info = True
            
            kogift_product_info_exists.append(has_kogift_info)
        
        logging.info(f"Pre-computed Koreagift product info existence for {len(kogift_product_info_exists)} rows")
        logging.info(f"Found {sum(kogift_product_info_exists)} rows with Koreagift product info")

        # Apply results to DataFrame
        mismatch_count = 0
        naver_mismatch_count = 0
        
        # Keep track of used Haereum images
        used_haereum_images = set()
        
        for idx, (match_set, product_name) in enumerate(zip(verified_matches, product_names)):
            if idx >= len(result_df):
                continue
                
            if match_set:
                haereum_data, kogift_data, naver_data = match_set
                
                # Process Haereum image
                if haereum_data and isinstance(haereum_data, tuple) and len(haereum_data) >= 2:
                    haereum_path, haereum_score = haereum_data[:2]  # Correctly extract path and score
                    if haereum_path and haereum_path in haereum_images:
                        used_haereum_images.add(haereum_path)
                        haereum_image_info_from_metadata = haereum_images[haereum_path] # Metadata from disk scan
                        
                        # Determine web URL for the Haereum image
                        current_haereum_url = None
                        
                        # 1. Try extracting from existing image dict in the input df
                        if idx < len(df) and 'ë³¸ì‚¬ ì´ë¯¸ì§€' in df.columns and isinstance(df.iloc[idx].get('ë³¸ì‚¬ ì´ë¯¸ì§€'), dict):
                            url_from_dict = df.iloc[idx]['ë³¸ì‚¬ ì´ë¯¸ì§€'].get('url')
                            if isinstance(url_from_dict, str) and url_from_dict.startswith(('http://', 'https://')):
                                current_haereum_url = url_from_dict
                        
                        # 2. Fallback: Check a separate URL column in input df (e.g., 'ë³¸ì‚¬ì´ë¯¸ì§€URL')
                        if not current_haereum_url and idx < len(df) and scraped_haereum_url_col_input_df in df.columns:
                            url_val_from_separate_col = df.iloc[idx].get(scraped_haereum_url_col_input_df)
                            if isinstance(url_val_from_separate_col, str) and url_val_from_separate_col.startswith(('http://', 'https://')):
                                current_haereum_url = url_val_from_separate_col
                        
                        # 3. Fallback: URL from metadata (less likely to be a web URL)
                        if not current_haereum_url:
                            current_haereum_url = haereum_image_info_from_metadata.get('url', '')

                        image_data = {
                            'url': current_haereum_url, 
                            'local_path': haereum_image_info_from_metadata.get('path', haereum_path),
                            'source': 'haereum',
                            'product_name': product_name,
                            'similarity': haereum_score,
                            'original_path': haereum_path
                        }
                        result_df.at[idx, 'ë³¸ì‚¬ ì´ë¯¸ì§€'] = image_data
                        
                        # Also update the separate URL column in result_df for consistency if it exists
                        if scraped_haereum_url_col_input_df not in result_df.columns:
                            result_df[scraped_haereum_url_col_input_df] = None
                        result_df.at[idx, scraped_haereum_url_col_input_df] = image_data['url']
                
                # Process Kogift image
                if kogift_data and isinstance(kogift_data, tuple) and len(kogift_data) >= 2:
                    kogift_path, kogift_score = kogift_data[:2]
                    if kogift_path and kogift_path in kogift_images:
                        has_kogift_product_info = idx < len(kogift_product_info_exists) and kogift_product_info_exists[idx]
                        if has_kogift_product_info:
                            kogift_image_info_from_metadata = kogift_images[kogift_path]
                            
                            current_kogift_url = None
                            original_url_for_dict = None
                            original_crawled_url_for_dict = None

                            # 1. Check URL from the dictionary in the input df's 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€' column
                            input_kogift_dict = None
                            if idx < len(df) and 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€' in df.columns and isinstance(df.iloc[idx].get('ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'), dict):
                                input_kogift_dict = df.iloc[idx]['ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€']
                                url_from_dict = input_kogift_dict.get('url')
                                if isinstance(url_from_dict, str) and url_from_dict.startswith(('http://', 'https://')):
                                    current_kogift_url = url_from_dict
                                # Preserve original_url and original_crawled_url if they exist in the input dict
                                original_url_for_dict = input_kogift_dict.get('original_url')
                                original_crawled_url_for_dict = input_kogift_dict.get('original_crawled_url')
                            
                            # 2. Fallback: Check a separate URL column in input df (e.g., 'ê³ ë ¤ê¸°í”„íŠ¸ì´ë¯¸ì§€URL')
                            if not current_kogift_url and idx < len(df) and scraped_kogift_url_col_input_df in df.columns:
                                url_val_from_separate_col = df.iloc[idx].get(scraped_kogift_url_col_input_df)
                                if isinstance(url_val_from_separate_col, str) and url_val_from_separate_col.startswith(('http://', 'https://')):
                                    current_kogift_url = url_val_from_separate_col
                            
                            # 3. Fallback: URL from metadata (less likely to be a web URL)
                            if not current_kogift_url:
                                current_kogift_url = kogift_image_info_from_metadata.get('url', '')
                            
                            # If original_url/original_crawled_url were not in input_dict, try metadata
                            if not original_url_for_dict:
                                original_url_for_dict = kogift_image_info_from_metadata.get('original_url')
                            if not original_crawled_url_for_dict:
                                original_crawled_url_for_dict = kogift_image_info_from_metadata.get('original_crawled_url')

                            image_data = {
                                'url': current_kogift_url, 
                                'local_path': kogift_image_info_from_metadata.get('path', kogift_path),
                                'source': 'kogift',
                                'product_name': product_name,
                                'similarity': kogift_score,  
                                'original_path': kogift_path,
                                'original_url': original_url_for_dict,
                                'original_crawled_url': original_crawled_url_for_dict
                            }
                            result_df.at[idx, 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'] = image_data
                            logger.info(f"Row {idx} ('{product_name}'): Assigned Kogift image '{os.path.basename(kogift_path)}' with URL: {current_kogift_url}")
                        else:
                            logger.warning(f"Row {idx} ('{product_name}'): Matched Kogift image '{os.path.basename(kogift_path)}' (Score: {kogift_score:.4f}) BUT product info missing. Discarding image.")
                            mismatch_count += 1
                    else:
                        logger.warning(f"Row {idx} ('{product_name}'): Kogift matched path '{kogift_path}' not in kogift_images dict or path is None.")
                elif kogift_data: # Matched but not in expected tuple format
                    logger.warning(f"Row {idx} ('{product_name}'): Kogift image matched but data format unexpected: {kogift_data}")
                else: # No Kogift match found by find_best_image_matches
                    logger.debug(f"Row {idx} ('{product_name}'): No Kogift image matched by find_best_image_matches.")

                # Process Naver image
                if naver_data and isinstance(naver_data, tuple) and len(naver_data) >= 2:
                    naver_path, naver_score = naver_data[:2]  # Correctly extract path and score
                    if naver_path and naver_path in naver_images:
                        # Check if there's Naver product info
                        naver_info_exists = False
                        
                        # Check for Naver link
                        naver_link_col = 'ë„¤ì´ë²„ ì‡¼í•‘ ë§í¬'
                        if naver_link_col in result_df.columns and pd.notna(result_df.at[idx, naver_link_col]) and result_df.at[idx, naver_link_col] not in ['', '-', 'None', None]:
                            naver_info_exists = True
                            
                        # Check for alternative Naver link column
                        alt_naver_link_col = 'ë„¤ì´ë²„ ë§í¬'
                        if not naver_info_exists and alt_naver_link_col in result_df.columns and pd.notna(result_df.at[idx, alt_naver_link_col]) and result_df.at[idx, alt_naver_link_col] not in ['', '-', 'None', None]:
                            naver_info_exists = True
                            
                        # Check for Naver price
                        naver_price_cols = ['íŒë§¤ë‹¨ê°€(Ví¬í•¨)(3)', 'ë„¤ì´ë²„ íŒë§¤ë‹¨ê°€']
                        for price_col in naver_price_cols:
                            if not naver_info_exists and price_col in result_df.columns and pd.notna(result_df.at[idx, price_col]) and result_df.at[idx, price_col] not in [0, '-', '', None]:
                                naver_info_exists = True
                                break
                                
                        # For Naver, we're more lenient - still add the image even without product info,
                        # but log the mismatch for tracking
                        if not naver_info_exists:
                            naver_mismatch_count += 1
                            logging.warning(f"Adding Naver image despite missing product info: {product_name}")
                            
                        naver_image_info_from_metadata = naver_images[naver_path]
                        
                        current_naver_image_url = None
                        product_page_url_for_dict = None

                        # 1. Check URL from the dictionary in the input df's 'ë„¤ì´ë²„ ì´ë¯¸ì§€' column
                        input_naver_dict = None
                        if idx < len(df) and 'ë„¤ì´ë²„ ì´ë¯¸ì§€' in df.columns and isinstance(df.iloc[idx].get('ë„¤ì´ë²„ ì´ë¯¸ì§€'), dict):
                            input_naver_dict = df.iloc[idx]['ë„¤ì´ë²„ ì´ë¯¸ì§€']
                            url_from_dict = input_naver_dict.get('url') # This should be direct image URL
                            if isinstance(url_from_dict, str) and (('phinf.pstatic.net' in url_from_dict) or any(url_from_dict.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif'])):
                                current_naver_image_url = url_from_dict
                            # Preserve product_page_url if it exists and is not an image URL
                            prod_page_url = input_naver_dict.get('product_page_url')
                            if isinstance(prod_page_url, str) and prod_page_url.startswith(('http://', 'https://')) and not (('phinf.pstatic.net' in prod_page_url) or any(prod_page_url.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif'])):
                                product_page_url_for_dict = prod_page_url
                        
                        # 2. Fallback: Check a separate URL column in input df for direct image URL
                        if not current_naver_image_url and idx < len(df) and scraped_naver_url_col_input_df in df.columns:
                            url_val_from_separate_col = df.iloc[idx].get(scraped_naver_url_col_input_df)
                            if isinstance(url_val_from_separate_col, str) and (('phinf.pstatic.net' in url_val_from_separate_col) or any(url_val_from_separate_col.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif'])):
                                current_naver_image_url = url_val_from_separate_col
                        
                        # 3. Fallback: URL from metadata (less likely to be a direct image web URL)
                        if not current_naver_image_url:
                            meta_url = naver_image_info_from_metadata.get('url')
                            if isinstance(meta_url, str) and (('phinf.pstatic.net' in meta_url) or any(meta_url.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif'])):
                                current_naver_image_url = meta_url

                        # For product_page_url, if not found in input_dict, try metadata's product_url
                        if not product_page_url_for_dict:
                            meta_prod_page_url = naver_image_info_from_metadata.get('product_url')
                            if isinstance(meta_prod_page_url, str) and meta_prod_page_url.startswith(('http://', 'https://')) and not (('phinf.pstatic.net' in meta_prod_page_url) or any(meta_prod_page_url.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif'])):
                                product_page_url_for_dict = meta_prod_page_url
                        
                        # Calculate actual image similarity for Naver images if needed
                        final_naver_score = naver_score
                        needs_recalc = naver_image_info_from_metadata.get('needs_image_similarity_calc', False)
                        
                        if needs_recalc and config.getboolean('ImageFiltering', 'enable_naver_image_similarity', fallback=True):
                            # Use enhanced image matcher to calculate real similarity
                            if enhanced_matcher and hasattr(enhanced_matcher, 'calculate_similarity') and os.path.exists(haereum_path):
                                naver_local_path = naver_image_info_from_metadata.get('path', naver_path)
                                if naver_local_path and os.path.exists(naver_local_path):
                                    try:
                                        image_similarity = enhanced_matcher.calculate_similarity(haereum_path, naver_local_path)
                                        logger.info(f"ğŸ” ì‹¤ì œ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê³„ì‚° - {product_name}: {image_similarity:.3f} (ê¸°ì¡´ í…ìŠ¤íŠ¸ ê¸°ë°˜: {naver_score:.3f})")
                                        final_naver_score = image_similarity
                                    except Exception as e:
                                        logger.warning(f"ë„¤ì´ë²„ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨ - {product_name}: {e}")
                                        final_naver_score = naver_score  # Keep original score on error
                                else:
                                    logger.warning(f"ë„¤ì´ë²„ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ - {product_name}: {naver_local_path}")
                                    final_naver_score = naver_score  # Keep original score if file missing
                            else:
                                logger.debug(f"Enhanced matcher ì‚¬ìš© ë¶ˆê°€ - {product_name}: í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ìœ ì§€")
                                final_naver_score = naver_score  # Keep original score if enhanced matcher unavailable
                        else:
                            # Use original score if recalculation not needed or disabled
                            final_naver_score = naver_score
                        
                        image_data = {
                            'url': current_naver_image_url, 
                            'local_path': naver_image_info_from_metadata.get('path', naver_path),
                            'source': 'naver',
                            'product_name': product_name,
                            'similarity': final_naver_score,  # Use calculated similarity
                            'original_path': naver_path,
                            'product_page_url': product_page_url_for_dict
                        }
                        result_df.at[idx, 'ë„¤ì´ë²„ ì´ë¯¸ì§€'] = image_data
                        
                        # Logic for 'ë„¤ì´ë²„ ì‡¼í•‘ ë§í¬' (product page link in result_df)
                        shopping_link_col_in_result_df = 'ë„¤ì´ë²„ ì‡¼í•‘ ë§í¬'
                        final_product_page_link = None

                        # A. Prioritize product_page_url_for_dict if available from above
                        if product_page_url_for_dict:
                            final_product_page_link = product_page_url_for_dict
                        
                        # B. Fallback to checking a separate 'ë„¤ì´ë²„ ì‡¼í•‘ ë§í¬' column in the input df
                        if not final_product_page_link and idx < len(df) and shopping_link_col_in_result_df in df.columns:
                             url_val_from_input_shopping_link_col = df.iloc[idx].get(shopping_link_col_in_result_df)
                             if isinstance(url_val_from_input_shopping_link_col, str) and url_val_from_input_shopping_link_col.startswith(('http://', 'https://')) and not (('phinf.pstatic.net' in url_val_from_input_shopping_link_col) or any(url_val_from_input_shopping_link_col.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif'])):
                                 final_product_page_link = url_val_from_input_shopping_link_col
                        
                        # C. Fallback to naver_image_info_from_metadata's product_url or url if it's a page link (already covered by product_page_url_for_dict logic)
                        # No new logic needed here for C as it's incorporated into product_page_url_for_dict

                        if final_product_page_link:
                            if shopping_link_col_in_result_df not in result_df.columns: result_df[shopping_link_col_in_result_df] = None
                            # Set only if current value is empty/placeholder OR if the new link is different and valid
                            current_shopping_link_val = result_df.at[idx, shopping_link_col_in_result_df]
                            if not pd.notna(current_shopping_link_val) or current_shopping_link_val in ['', '-', 'None', None] or current_shopping_link_val != final_product_page_link:
                                result_df.at[idx, shopping_link_col_in_result_df] = final_product_page_link
        
        # Final check: Ensure EVERY row has a Haereum image 
        # If any row is missing a Haereum image, assign a random one
        haereum_count_before = sum(1 for i in range(len(result_df)) if isinstance(result_df.at[i, 'ë³¸ì‚¬ ì´ë¯¸ì§€'], dict))
        haereum_added_count = 0
        
        # Get available Haereum images that haven't been used yet
        available_haereum = [path for path in haereum_images if path not in used_haereum_images]
        if not available_haereum and haereum_images:
            # If all images are used but we still need more, reset and use them again
            available_haereum = list(haereum_images.keys())
            remaining_rows = sum(1 for i in range(len(result_df)) if not isinstance(result_df.at[i, 'ë³¸ì‚¬ ì´ë¯¸ì§€'], dict))
            logging.info(f"All {len(haereum_images)} Haereum images have been used. Reusing images for {remaining_rows} remaining rows to ensure complete coverage.")
        
        for idx in range(len(result_df)):
            if idx >= len(result_df):
                continue
                
            # Check if this row is missing a Haereum image
            try:
                haereum_img_value = result_df.at[idx, 'ë³¸ì‚¬ ì´ë¯¸ì§€']
                if not isinstance(haereum_img_value, dict):
                    product_name = result_df.at[idx, 'ìƒí’ˆëª…'] if 'ìƒí’ˆëª…' in result_df.columns else f"Row {idx+1}"
                    logging.info(f"Row {idx} ('{product_name}'): Missing Haereum image. Assigning available image for complete coverage.")
                else:
                    continue  # Already has a valid image, skip to next row
            except Exception as e:
                logging.error(f"Error checking Haereum image for row {idx}: {e}")
                product_name = f"Row {idx+1}"
                
                # Assign a random Haereum image
                if available_haereum:
                    haereum_path = available_haereum.pop(0)  # Take the first available
                    if not available_haereum and haereum_images:
                        # If we ran out, reset the list
                        available_haereum = list(haereum_images.keys())
                    
                    haereum_image_info_from_metadata = haereum_images[haereum_path]
                    
                    # Create image data
                    image_data = {
                        'url': haereum_image_info_from_metadata.get('url', ''), 
                        'local_path': haereum_image_info_from_metadata.get('path', haereum_path),
                        'source': 'haereum',
                        'product_name': product_name,
                        'similarity': 0.01,  # Very low score to indicate this is a desperate assignment
                        'original_path': haereum_path
                    }
                    result_df.at[idx, 'ë³¸ì‚¬ ì´ë¯¸ì§€'] = image_data
                    haereum_added_count += 1
        
        # Log the results of ensuring Haereum images
        haereum_count_after = sum(1 for i in range(len(result_df)) if isinstance(result_df.at[i, 'ë³¸ì‚¬ ì´ë¯¸ì§€'], dict))
        logging.info(f"Haereum image count: {haereum_count_before} -> {haereum_count_after} (Added {haereum_added_count} random images)")
        
        # ì´ë¯¸ì§€ ê²½ë¡œ ë¶ˆì¼ì¹˜ ìˆ˜ì • (ë¡œì»¬ íŒŒì¼ì´ ì´ë™ëœ ê²½ìš°)
        for idx in range(len(result_df)):
            if idx >= len(result_df):
                continue
                
            # Check and fix Koreagift image paths
            kogift_img = result_df.at[idx, 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€']
            if isinstance(kogift_img, dict) and 'local_path' in kogift_img:
                local_path = kogift_img['local_path']
                if not os.path.exists(local_path):
                    # Try to find the file in the Kogift directory by basename
                    basename = os.path.basename(local_path)
                    for directory in [kogift_dir, main_img_dir]:
                        possible_path = os.path.join(directory, basename)
                        if os.path.exists(possible_path):
                            kogift_img['local_path'] = possible_path
                            result_df.at[idx, 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'] = kogift_img
                            logging.info(f"Fixed Koreagift image path from {local_path} to {possible_path}")
                            break
            
            # Check and fix Naver image paths
            naver_img = result_df.at[idx, 'ë„¤ì´ë²„ ì´ë¯¸ì§€']
            if isinstance(naver_img, dict) and 'local_path' in naver_img:
                local_path = naver_img['local_path']
                if not os.path.exists(local_path):
                    # Try to find the file in the Naver directory by basename or URL hash
                    basename = os.path.basename(local_path)
                    url_hash = None
                    if 'url' in naver_img and naver_img['url']:
                        url_hash = hashlib.md5(naver_img['url'].encode()).hexdigest()[:10]
                    
                    found = False
                    for directory in [naver_dir, main_img_dir]:
                        if os.path.exists(directory):
                            for filename in os.listdir(directory):
                                file_path = os.path.join(directory, filename)
                                if os.path.isfile(file_path) and (
                                    basename == filename or 
                                    (url_hash and url_hash in filename)
                                ):
                                    naver_img['local_path'] = file_path
                                    result_df.at[idx, 'ë„¤ì´ë²„ ì´ë¯¸ì§€'] = naver_img
                                    logging.info(f"Fixed Naver image path from {local_path} to {file_path}")
                                    found = True
                                    break
                        if found:
                            break
        
        # Count final images
        haereum_count = result_df['ë³¸ì‚¬ ì´ë¯¸ì§€'].apply(lambda x: isinstance(x, dict)).sum()
        kogift_count = result_df['ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'].apply(lambda x: isinstance(x, dict)).sum()
        naver_count = result_df['ë„¤ì´ë²„ ì´ë¯¸ì§€'].apply(lambda x: isinstance(x, dict)).sum()
        
        logging.info(f"í†µí•©: ì´ë¯¸ì§€ ë§¤ì¹­ ì™„ë£Œ - í•´ì˜¤ë¦„: {haereum_count}ê°œ, ê³ ë ¤ê¸°í”„íŠ¸: {kogift_count}ê°œ, ë„¤ì´ë²„: {naver_count}ê°œ")
        
        return result_df
    
    except Exception as e:
        logging.error(f"í†µí•©: ì´ë¯¸ì§€ í†µí•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return df

def improved_kogift_image_matching(df: pd.DataFrame) -> pd.DataFrame:
    """
    ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€ ë§¤ì¹­ ê°œì„  í•¨ìˆ˜
    
    ì´ë¯¸ì§€ URLì´ ëˆ„ë½ë˜ì—ˆê±°ë‚˜ ì˜ëª»ëœ ê²½ìš° ì‹¤ì œ ìƒí’ˆ ë§í¬ë¥¼ í™œìš©í•´ ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ URLì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        df: í˜„ì¬ DataFrame
        
    Returns:
        updated DataFrame with improved Kogift image URLs
    """
    try:
        if 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€' not in df.columns or 'ê³ ë ¤ê¸°í”„íŠ¸ ìƒí’ˆë§í¬' not in df.columns:
            logging.warning("í•„ìš”í•œ ì»¬ëŸ¼(ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€ ë˜ëŠ” ê³ ë ¤ê¸°í”„íŠ¸ ìƒí’ˆë§í¬)ì´ ì—†ì–´ ì´ë¯¸ì§€ ë§í¬ ìˆ˜ì • ë¶ˆê°€")
            return df
        
        update_count = 0
        result_df = df.copy()
        
        for idx, row in result_df.iterrows():
            # Check if already has a valid URL
            img_data = row.get('ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€')
            if not isinstance(img_data, dict):
                continue
                
            # Check if URL is missing or a placeholder
            url = img_data.get('url')
            if url and isinstance(url, str) and not url.startswith('http://placeholder.url/') and url.startswith(('http://', 'https://')):
                # ì´ë¯¸ ìœ íš¨í•œ URLì´ ìˆëŠ” ê²½ìš°
                continue
                
            # Check if we have an original_url - ì¶”ê°€ëœ ë¶€ë¶„
            original_url = img_data.get('original_url')
            if original_url and isinstance(original_url, str) and original_url.startswith(('http://', 'https://')):
                # ì›ë³¸ URL ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
                img_data['url'] = original_url
                result_df.at[idx, 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'] = img_data
                update_count += 1
                logging.info(f"Row {idx}: Using original URL {original_url[:50]}... for Kogift image")
                continue
                
            # Check if we have an original_crawled_url
            original_crawled_url = img_data.get('original_crawled_url')
            if original_crawled_url and isinstance(original_crawled_url, str) and original_crawled_url.startswith(('http://', 'https://')):
                # original_crawled_url ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
                img_data['url'] = original_crawled_url
                result_df.at[idx, 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'] = img_data
                update_count += 1
                logging.info(f"Row {idx}: Using original crawled URL {original_crawled_url[:50]}... for Kogift image")
                continue
                
            # ìƒí’ˆ ë§í¬ê°€ ìˆëŠ”ì§€ í™•ì¸
            product_link = row.get('ê³ ë ¤ê¸°í”„íŠ¸ ìƒí’ˆë§í¬')
            if not product_link or not isinstance(product_link, str) or not product_link.startswith(('http://', 'https://')):
                continue
                
            # Get product code from URL
            try:
                # ìƒí’ˆ ì½”ë“œ ì¶”ì¶œ (URL íŒ¨í„´ì— ë”°ë¼ ì¡°ì • í•„ìš”)
                product_code = None
                
                # URLì—ì„œ ìƒí’ˆ ì½”ë“œ ì¶”ì¶œ ì‹œë„ (ì—¬ëŸ¬ íŒ¨í„´ ì§€ì›)
                if 'goods_view.php' in product_link:
                    # goods_view.php?goodsno=12345 íŒ¨í„´ ì²˜ë¦¬
                    parts = product_link.split('goodsno=')
                    if len(parts) > 1:
                        product_code = parts[1].split('&')[0]
                elif '/goods/' in product_link:
                    # /goods/1234 íŒ¨í„´ ì²˜ë¦¬
                    parts = product_link.split('/goods/')
                    if len(parts) > 1:
                        product_code = parts[1].split('/')[0].split('?')[0]
                elif 'goodsDetail' in product_link:
                    # goodsDetail?goodsNo=1234 íŒ¨í„´ ì²˜ë¦¬
                    parts = product_link.split('goodsNo=')
                    if len(parts) > 1:
                        product_code = parts[1].split('&')[0]
                # ê³ ë ¤ê¸°í”„íŠ¸ íŠ¹í™” íŒ¨í„´
                elif 'no=' in product_link:
                    # ê³ ë ¤ê¸°í”„íŠ¸ URL íŒ¨í„´ ì²˜ë¦¬ (no=12345)
                    parts = product_link.split('no=')
                    if len(parts) > 1:
                        product_code = parts[1].split('&')[0]
                
                if not product_code:
                    logging.warning(f"Row {idx}: ìƒí’ˆ ë§í¬ì—ì„œ ì½”ë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ: {product_link}")
                    # ìƒí’ˆ ì½”ë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” ê²½ìš° ìƒí’ˆ ë§í¬ ìì²´ë¥¼ ì´ë¯¸ì§€ URLë¡œ ì‚¬ìš©
                    img_data['url'] = product_link
                    img_data['original_url'] = product_link  # ì¶”ê°€: ì›ë³¸ URL ì €ì¥
                    result_df.at[idx, 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'] = img_data
                    update_count += 1
                    logging.info(f"Row {idx}: ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨, ìƒí’ˆ ë§í¬ë¥¼ ì´ë¯¸ì§€ URLë¡œ ì‚¬ìš© - {product_link}")
                    continue
                    
                # ìƒí’ˆ ì´ë¯¸ì§€ URL ìƒì„±
                if 'koreagift.com' in product_link.lower():
                    # ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€ íŒ¨í„´
                    # 1. ê¸°ë³¸ íŒ¨í„´: shop_{product_code}.jpg
                    # Ensure product_code is just the base number (e.g., 1707873892937710, not 1707873892937710_0)
                    image_url = f"https://koreagift.com/ez/upload/mall/shop_{product_code}_0.jpg"
                else:
                    # ì¼ë°˜ì ì¸ ì‡¼í•‘ëª° ì´ë¯¸ì§€ íŒ¨í„´
                    domain_parts = product_link.split('/')
                    if len(domain_parts) > 2:
                        base_domain = domain_parts[2]
                        image_url = f"https://{base_domain}/data/item/goods{product_code}/thumb-{product_code}_500x500.jpg"
                    else:
                        # ë„ë©”ì¸ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” ê²½ìš° ìƒí’ˆ ë§í¬ ìì²´ë¥¼ ì´ë¯¸ì§€ URLë¡œ ì‚¬ìš©
                        image_url = product_link
                        logging.warning(f"Row {idx}: ìƒí’ˆ ë§í¬ {product_link}ì—ì„œ ë„ë©”ì¸ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ì–´ ìƒí’ˆ ë§í¬ ìì²´ë¥¼ ì‚¬ìš©")
                
                # ê¸°ì¡´ ì´ë¯¸ì§€ ë°ì´í„° ì—…ë°ì´íŠ¸
                img_data['url'] = image_url
                img_data['original_url'] = image_url  # ì¶”ê°€: ì›ë³¸ URL ì €ì¥
                img_data['original_crawled_url'] = image_url  # ì¶”ê°€: í¬ë¡¤ë§ëœ URL ì €ì¥
                img_data['product_id'] = product_code  # ì¶”ê°€: ìƒí’ˆ ì½”ë“œ ì €ì¥
                result_df.at[idx, 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'] = img_data
                update_count += 1
                logging.debug(f"Row {idx}: ê³ ë ¤ê¸°í”„íŠ¸ URL ì¶”ê°€ - {image_url}")
                
            except Exception as e:
                logging.error(f"Row {idx}: ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€ URL ìƒì„± ì˜¤ë¥˜ - {str(e)}")
                # ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°ì—ë„ ìƒí’ˆ ë§í¬ ìì²´ë¥¼ ì´ë¯¸ì§€ URLë¡œ ì‚¬ìš©
                if product_link and isinstance(product_link, str) and product_link.startswith(('http://', 'https://')):
                    img_data['url'] = product_link
                    img_data['original_url'] = product_link
                    result_df.at[idx, 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'] = img_data
                    update_count += 1
                    logging.info(f"Row {idx}: ì˜¤ë¥˜ ë°œìƒ, ìƒí’ˆ ë§í¬ë¥¼ ì´ë¯¸ì§€ URLë¡œ ì‚¬ìš© - {product_link}")
                continue
                
        logging.info(f"improved_kogift_image_matching fixed {update_count} image links")
        return result_df
        
    except Exception as e:
        logging.error(f"ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€ ë§í¬ ê°œì„  ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return df

def integrate_and_filter_images(df: pd.DataFrame, config: configparser.ConfigParser, 
                            save_excel_output=False) -> pd.DataFrame:
    """
    Integrates and filters images from all sources, applying strict quality controls.
    
    This function performs the following steps:
    1. Integrate images from all sources with higher thresholds
    2. Improve Kogift image matching
    3. Apply strict filtering based on similarity scores
    4. Perform URL validation to reject invalid URLs (especially front/ URLs)
    5. Final quality control check
    
    Args:
        df: DataFrame with product data
        config: Configuration settings
        save_excel_output: Whether to save an Excel output file with images
        
    Returns:
        DataFrame with high-quality integrated and filtered images
    """
    logger.info("Integrating and filtering images with enhanced quality controls")
    
    # Step 1: Integrate images from all sources with higher thresholds
    df_with_images = integrate_images(df, config)
    logger.info(f"Image integration completed. DataFrame shape: {df_with_images.shape}")
    
    # Step 2: Improve Kogift image matching
    logger.info("Improving Kogift image matching with strict quality controls...")
    df_kogift_improved = improved_kogift_image_matching(df_with_images)
    logger.info(f"Kogift image matching improvement completed. DataFrame shape: {df_kogift_improved.shape}")
    
    # Step 3: Apply image filtering based on similarity and URL validity
    df_filtered = filter_images_by_similarity(df_kogift_improved, config)
    logger.info(f"Image filtering completed. DataFrame shape: {df_filtered.shape}")
    
    result_df = df_filtered.copy()
    
    # Ensure essential image columns exist in result_df before further processing and counting
    # This is crucial if any of the upstream functions returned the original df without these columns due to an error.
    required_image_columns = ['ë³¸ì‚¬ ì´ë¯¸ì§€', 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€', 'ë„¤ì´ë²„ ì´ë¯¸ì§€']
    for col_name in required_image_columns:
        if col_name not in result_df.columns:
            logger.warning(f"Column '{col_name}' missing in result_df before final validation and counting. Adding it with None values.")
            result_df[col_name] = None
            
    # Step 4: Final validation - ensure all URLs are valid and reject any problematic images
    # Now with less strict validation for Naver images
    logger.info("Performing final URL validation and quality check...")
    
    # Add an ImageFiltering section to config if it doesn't exist
    if 'ImageFiltering' not in config:
        config.add_section('ImageFiltering')
    
    # Get validation settings from config
    try:
        skip_naver_validation = config.getboolean('ImageFiltering', 'skip_naver_validation', fallback=True)
    except (configparser.NoSectionError, configparser.NoOptionError):
        skip_naver_validation = True  # Default to skipping Naver validation to avoid filtering
    
    for idx in range(len(result_df)):
        product_name = result_df.at[idx, 'ìƒí’ˆëª…'] if 'ìƒí’ˆëª…' in result_df.columns else f"Index {idx}"
        
        # Check Naver image URLs - much more lenient validation
        if 'ë„¤ì´ë²„ ì´ë¯¸ì§€' in result_df.columns:
            naver_data = result_df.at[idx, 'ë„¤ì´ë²„ ì´ë¯¸ì§€']
            if isinstance(naver_data, dict):
                # Check if there's a valid local_path
                local_path = naver_data.get('local_path')
                has_valid_local_path = local_path and os.path.exists(str(local_path))
                
                # Check URL validity but be very lenient
                url = naver_data.get('url')
                has_valid_url = url and isinstance(url, str) and url.startswith(('http://', 'https://'))
                
                # Special case: Keep Naver images with valid local path even without valid URL
                if has_valid_local_path:
                    logger.info(f"Row {idx} (Product: '{product_name}'): Keeping Naver image with invalid URL but valid local path.")
                    
                    # Try to fix/add URL from other available data
                    original_path = naver_data.get('original_path')
                    image_url = naver_data.get('original_url')
                    product_id = naver_data.get('product_id')
                    
                    # Try to find a valid URL but don't clear data if none found
                    if not has_valid_url:
                        if image_url and isinstance(image_url, str) and image_url.startswith(('http://', 'https://')):
                            naver_data['url'] = image_url
                        elif original_path and isinstance(original_path, str) and original_path.startswith(('http://', 'https://')):
                            naver_data['url'] = original_path
                        elif product_id:
                            # Construct URL from product_id as a last resort
                            constructed_url = f"https://shopping-phinf.pstatic.net/main_{product_id}/{product_id}.jpg"
                            naver_data['url'] = constructed_url
                            logger.info(f"Row {idx}: Constructed Naver URL from product_id: {constructed_url}")
                    
                    # Update DataFrame with possibly updated naver_data
                    result_df.at[idx, 'ë„¤ì´ë²„ ì´ë¯¸ì§€'] = naver_data
                elif not has_valid_url and skip_naver_validation:
                    # If we're skipping validation and there's no valid URL, warn but don't remove
                    logger.warning(f"Row {idx}: No valid URL found for Naver image, but keeping data due to skip_naver_validation=True.")
                elif not has_valid_url and not has_valid_local_path:
                    # Only clear if both URL and local file are invalid AND we're not skipping validation
                    logger.warning(f"Row {idx}: No valid URL or local path found for Naver image. Clearing Naver image data.")
                    result_df.at[idx, 'ë„¤ì´ë²„ ì´ë¯¸ì§€'] = None
                else:
                    # For all other cases, keep the data as is
                    pass
    
    # Count valid images after all processing
    naver_count = sum(1 for i in range(len(result_df)) if isinstance(result_df.at[i, 'ë„¤ì´ë²„ ì´ë¯¸ì§€'], dict))
    kogift_count = sum(1 for i in range(len(result_df)) if isinstance(result_df.at[i, 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'], dict))
    haereum_count = sum(1 for i in range(len(result_df)) if isinstance(result_df.at[i, 'ë³¸ì‚¬ ì´ë¯¸ì§€'], dict))
    
    logger.info(f"Final image counts after validation: Haereum={haereum_count}, Kogift={kogift_count}, Naver={naver_count}")
    
    # Save Excel output if requested
    if save_excel_output:
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            excel_output = f"image_integration_result_{timestamp}.xlsx"
            
            # Note: Excel creation functionality would need to be implemented separately
            logger.info(f"Excel output requested but create_excel_with_images function not available. Would create: {excel_output}")
        except Exception as e:
            logger.error(f"Error preparing Excel output: {e}")
    
    return result_df

def filter_images_by_similarity(df: pd.DataFrame, config: configparser.ConfigParser) -> pd.DataFrame:
    """
    Filter images based on similarity scores and URL validity.
    When an image is filtered out, also clear related data columns.
    
    Args:
        df: DataFrame containing image data
        config: Configuration settings
        
    Returns:
        Filtered DataFrame
    """
    logger.info("Filtering images based on similarity scores...")
    
    # Get similarity thresholds from config
    try:
        # General threshold for all images
        similarity_threshold = config.getfloat('ImageFiltering', 'similarity_threshold', fallback=0.4)
        
        # Specific threshold for Naver images (more lenient)
        naver_similarity_threshold = config.getfloat('ImageFiltering', 'naver_similarity_threshold', fallback=0.3)
        
        # Specific threshold for Kogift images
        kogift_similarity_threshold = config.getfloat('ImageFiltering', 'kogift_similarity_threshold', fallback=0.25)
        
        # í•´ì˜¤ë¦„ ê¸°í”„íŠ¸(ë³¸ì‚¬) ì´ë¯¸ì§€ëŠ” ì„ê³„ê°’ í•„í„°ë§ì„ í•˜ì§€ ì•ŠìŒ (ë¬´ì¡°ê±´ ìœ ì§€)
        
    except (configparser.NoSectionError, configparser.NoOptionError):
        similarity_threshold = 0.4
        naver_similarity_threshold = 0.3  # Updated from 0.1 to match log
        kogift_similarity_threshold = 0.25  # Updated from 0.4 to match log
    
    logger.info(f"Using similarity thresholds - General: {similarity_threshold}, Naver: {naver_similarity_threshold}, Kogift: {kogift_similarity_threshold}, Haereum: Always kept (no filtering)")
    
    # Create a copy of the DataFrame to avoid modifying the original
    filtered_df = df.copy()
    
    # Define related columns for each image source
    naver_related_columns = [
        'ë„¤ì´ë²„ ì‡¼í•‘ ë§í¬', 'ê³µê¸‰ì‚¬ ìƒí’ˆë§í¬', 'ê³µê¸‰ì‚¬ëª…', 
        'íŒë§¤ë‹¨ê°€(Ví¬í•¨)(3)', 'ê°€ê²©ì°¨ì´(3)', 'ê°€ê²©ì°¨ì´(3)(%)', 
        'ê¸°ë³¸ìˆ˜ëŸ‰(3)'
    ]
    
    kogift_related_columns = [
        'ê³ ë ¤ê¸°í”„íŠ¸ ìƒí’ˆë§í¬', 'íŒë§¤ê°€(Ví¬í•¨)(2)', 'íŒë§¤ë‹¨ê°€(Ví¬í•¨)(2)',
        'ê°€ê²©ì°¨ì´(2)', 'ê°€ê²©ì°¨ì´(2)(%)', 'ê¸°ë³¸ìˆ˜ëŸ‰(2)'
    ]
    
    # Process each row
    for idx in range(len(filtered_df)):
        # Check each image source with specific thresholds
        for col_name in ['ë³¸ì‚¬ ì´ë¯¸ì§€', 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€', 'ë„¤ì´ë²„ ì´ë¯¸ì§€']:
            if col_name in filtered_df.columns:
                image_data = filtered_df.at[idx, col_name]
                
                # Skip if no image data
                if not isinstance(image_data, dict):
                    continue
                
                # Get similarity score - check both 'similarity' and 'score' keys
                score = image_data.get('similarity', image_data.get('score', 0.0))
                
                # Convert to float if it's a string
                if isinstance(score, str):
                    try:
                        score = float(score)
                    except ValueError:
                        logger.warning(f"Invalid similarity score format for {col_name} at row {idx}: {score}")
                        score = 0.0
                
                # Determine the appropriate threshold for this image type
                # í•´ì˜¤ë¦„ ê¸°í”„íŠ¸(ë³¸ì‚¬) ì´ë¯¸ì§€ëŠ” ë¬´ì¡°ê±´ ìœ ì§€ (í•„í„°ë§í•˜ì§€ ì•ŠìŒ)
                if 'ë³¸ì‚¬' in col_name:
                    logger.debug(f"Keeping {col_name} for row {idx} - Haereum images are always kept (score: {score:.3f})")
                    continue  # í•´ì˜¤ë¦„ ì´ë¯¸ì§€ëŠ” í•„í„°ë§í•˜ì§€ ì•Šê³  ê±´ë„ˆëœ€
                elif 'ë„¤ì´ë²„' in col_name:
                    threshold = naver_similarity_threshold
                    related_columns = naver_related_columns
                elif 'ê³ ë ¤ê¸°í”„íŠ¸' in col_name:
                    threshold = kogift_similarity_threshold
                    related_columns = kogift_related_columns
                else:
                    threshold = similarity_threshold
                    related_columns = []
                
                # Filter out low similarity scores (í•´ì˜¤ë¦„ ì´ë¯¸ì§€ ì œì™¸)
                if score < threshold:
                    logger.info(f"Filtering out {col_name} for row {idx} due to low similarity score: {score:.3f} < {threshold:.3f}")
                    
                    # Clear the image data
                    filtered_df.at[idx, col_name] = None
                    
                    # Clear related data columns
                    for related_col in related_columns:
                        if related_col in filtered_df.columns:
                            current_value = filtered_df.at[idx, related_col]
                            # Only clear if there's actual data (not already None or '-')
                            if current_value is not None and current_value != '-' and str(current_value).strip() != '':
                                logger.debug(f"Clearing related data in '{related_col}' for row {idx}: '{current_value}' -> '-'")
                                # Handle different column types properly
                                try:
                                    # For numeric columns, try to maintain type compatibility
                                    col_dtype = filtered_df[related_col].dtype
                                    if pd.api.types.is_numeric_dtype(col_dtype):
                                        # For numeric columns, use None instead of '-' to avoid dtype conflicts
                                        filtered_df.at[idx, related_col] = None
                                    else:
                                        # For object/string columns, use '-'
                                        filtered_df.at[idx, related_col] = '-'
                                except Exception as e:
                                    logger.debug(f"Error setting column type for {related_col}: {e}. Using string default.")
                                    filtered_df.at[idx, related_col] = '-'
                else:
                    logger.debug(f"Keeping {col_name} for row {idx} with similarity score: {score:.3f} >= {threshold:.3f}")
    
    return filtered_df

def print_system_status(config: configparser.ConfigParser = None):
    """ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì½˜ì†”ì— ì¶œë ¥í•©ë‹ˆë‹¤. (ë‹¨ìˆœí™”ëœ ë²„ì „)"""
    
    print("\n" + "="*60)
    print("ğŸš€ í•´ì‹œ ê¸°ë°˜ ì´ë¯¸ì§€ ë§¤ì¹­ ì‹œìŠ¤í…œ")
    print("="*60)
    print("âœ… í•´ì‹œ ë§¤ì¹­ë§Œ ì‚¬ìš©í•˜ëŠ” ë‹¨ìˆœí™”ëœ ì‹œìŠ¤í…œ")
    print("ğŸ“‹ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° ì—†ìŒ - íŒŒì¼ëª… í•´ì‹œê°’ìœ¼ë¡œë§Œ ë§¤ì¹­")
    print("ğŸ”§ ì„¤ì •: í•´ì‹œ ê¸°ë°˜ ì •í™•í•œ ë§¤ì¹­")
    print("="*60)

def get_image_integration_summary(df: pd.DataFrame) -> Dict[str, Any]:
    """
    ì´ë¯¸ì§€ í†µí•© ê²°ê³¼ì˜ ìš”ì•½ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ì´ë¯¸ì§€ê°€ í†µí•©ëœ DataFrame
        
    Returns:
        í†µí•© ê²°ê³¼ ìš”ì•½ ë”•ì…”ë„ˆë¦¬
    """
    try:
        summary = {
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'total_products': len(df),
            'image_counts': {
                'haereum': 0,
                'kogift': 0,
                'naver': 0
            },
            'success_rates': {
                'haereum': 0.0,
                'kogift': 0.0,
                'naver': 0.0
            }
        }
        
        # Count valid images for each source
        if 'ë³¸ì‚¬ ì´ë¯¸ì§€' in df.columns:
            summary['image_counts']['haereum'] = df['ë³¸ì‚¬ ì´ë¯¸ì§€'].apply(lambda x: isinstance(x, dict)).sum()
            summary['success_rates']['haereum'] = summary['image_counts']['haereum'] / len(df) * 100
            
        if 'ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€' in df.columns:
            summary['image_counts']['kogift'] = df['ê³ ë ¤ê¸°í”„íŠ¸ ì´ë¯¸ì§€'].apply(lambda x: isinstance(x, dict)).sum()
            summary['success_rates']['kogift'] = summary['image_counts']['kogift'] / len(df) * 100
            
        if 'ë„¤ì´ë²„ ì´ë¯¸ì§€' in df.columns:
            summary['image_counts']['naver'] = df['ë„¤ì´ë²„ ì´ë¯¸ì§€'].apply(lambda x: isinstance(x, dict)).sum()
            summary['success_rates']['naver'] = summary['image_counts']['naver'] / len(df) * 100
        
        return summary
        
    except Exception as e:
        logging.error(f"ì´ë¯¸ì§€ í†µí•© ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return {'error': str(e)}

def print_image_integration_summary(df: pd.DataFrame):
    """ì´ë¯¸ì§€ í†µí•© ê²°ê³¼ ìš”ì•½ì„ ì½˜ì†”ì— ì¶œë ¥í•©ë‹ˆë‹¤."""
    
    summary = get_image_integration_summary(df)
    
    print("\n" + "="*60)
    print("ğŸ–¼ï¸ ì´ë¯¸ì§€ í†µí•© ê²°ê³¼ ìš”ì•½")
    print("="*60)
    
    if 'error' in summary:
        print(f"âŒ ì˜¤ë¥˜: {summary['error']}")
        return
    
    print(f"ğŸ“… ì²˜ë¦¬ ì‹œê°„: {summary['timestamp']}")
    print(f"ğŸ“¦ ì´ ìƒí’ˆ ìˆ˜: {summary['total_products']}ê°œ")
    
    print(f"\nğŸ“Š ì´ë¯¸ì§€ ë§¤ì¹­ ê²°ê³¼:")
    for source, count in summary['image_counts'].items():
        success_rate = summary['success_rates'][source]
        source_name = {
            'haereum': 'í•´ì˜¤ë¦„(ë³¸ì‚¬)',
            'kogift': 'ê³ ë ¤ê¸°í”„íŠ¸', 
            'naver': 'ë„¤ì´ë²„'
        }.get(source, source)
        
        if count > 0:
            print(f"   {source_name}: âœ… {count}ê°œ ({success_rate:.1f}%)")
        else:
            print(f"   {source_name}: âŒ 0ê°œ (0.0%)")
    
    total_images = sum(summary['image_counts'].values())
    print(f"\nğŸ¯ ì „ì²´ ë§¤ì¹­ëœ ì´ë¯¸ì§€: {total_images}ê°œ")
    
    print("\n" + "="*60)