#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í•´ì‹œ ìƒì„± ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ë„¤ì´ë²„, í•´ì˜¤ë¦„, ê³ ë ¤ê¸°í”„íŠ¸ ê°„ í•´ì‹œ ìƒì„±ì´ ì¼ê´€ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
"""

import sys
import os
import hashlib

# PythonScript ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), 'PythonScript'))

try:
    from PythonScript.utils import generate_product_name_hash
    print("âœ… utils.generate_product_name_hash í•¨ìˆ˜ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì„í¬íŠ¸í–ˆìŠµë‹ˆë‹¤.")
except ImportError as e:
    print(f"âŒ utils.generate_product_name_hash ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    
    # Fallback í•¨ìˆ˜ ì •ì˜
    def generate_product_name_hash(product_name: str) -> str:
        """
        ìƒí’ˆëª…ìœ¼ë¡œë¶€í„° 16ìë¦¬ í•´ì‹œê°’ì„ ìƒì„±í•©ë‹ˆë‹¤ (Fallback ë²„ì „).
        """
        try:
            # ìƒí’ˆëª… ì •ê·œí™” (ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜)
            normalized_name = ''.join(product_name.split()).lower()
            # MD5 í•´ì‹œ ìƒì„± í›„ ì²« 16ìë¦¬ ì‚¬ìš©
            hash_obj = hashlib.md5(normalized_name.encode('utf-8'))
            return hash_obj.hexdigest()[:16]
        except Exception as e:
            print(f"Error generating hash for product name {product_name}: {e}")
            return ""

def test_hash_consistency():
    """í•´ì‹œ ìƒì„± ì¼ê´€ì„±ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("\n" + "="*60)
    print("ê³ ë ¤ê¸°í”„íŠ¸/ë„¤ì´ë²„/í•´ì˜¤ë¦„ í•´ì‹œ ì¼ê´€ì„± í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # í…ŒìŠ¤íŠ¸í•  ìƒí’ˆëª…ë“¤
    test_products = [
        "ëŒ€í˜• ì‚¬ë¬´ìš© ì§‘ê²Œí´ë¦½",
        "ëŒí”„ë¡œìŠ¤ ì•„íŠ¸ì½œë¼ ìê°œ ëª…í•¨ì¼€ì´ìŠ¤ ê²½ì£¼ ì²¨ì„±ëŒ€",
        "ë¡œí˜ë¦¬ì•„ í¬ë¡œìŠ¤ì˜¤ë²„ í•´ë³€ ë°”ìº‰ìŠ¤ ë¹„ì¹˜íƒ€ì˜¬ 230g",
        "ëª¨ìŠ¤ë‹ˆì— ì œë¡œì›¨ì´ìŠ¤íŠ¸ ëŒ€ë‚˜ë¬´ì¹«ì†”",
        "í•˜ëª¨ë‹ˆ ì‹¬í”Œì¹«ì†”ì„¸íŠ¸ 805"
    ]
    
    print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸í•  ìƒí’ˆ ìˆ˜: {len(test_products)}ê°œ")
    print("-" * 60)
    
    for i, product_name in enumerate(test_products, 1):
        print(f"\n{i}. ìƒí’ˆëª…: '{product_name}'")
        
        # í•´ì‹œ ìƒì„± (utils í•¨ìˆ˜ ì‚¬ìš©)
        name_hash = generate_product_name_hash(product_name)
        
        # ë‘ ë²ˆì§¸ í•´ì‹œ ìƒì„± (ê³ ë ¤ê¸°í”„íŠ¸ ë°©ì‹ê³¼ ë™ì¼)
        normalized_name = ''.join(product_name.split()).lower()
        second_hash = hashlib.md5(normalized_name.encode('utf-8')).hexdigest()[16:24]
        
        print(f"   ì •ê·œí™”ëœ ì´ë¦„: '{normalized_name}'")
        print(f"   ì²« ë²ˆì§¸ í•´ì‹œ (16ì): {name_hash}")
        print(f"   ë‘ ë²ˆì§¸ í•´ì‹œ (8ì): {second_hash}")
        
        # íŒŒì¼ëª… ìƒì„± (ê° í”Œë«í¼ë³„ë¡œ)
        platforms = ['kogift', 'naver', 'haereum']
        for platform in platforms:
            filename = f"{platform}_{name_hash}_{second_hash}.jpg"
            print(f"   {platform.upper()} íŒŒì¼ëª…: {filename}")

def test_normalize_function():
    """ì •ê·œí™” í•¨ìˆ˜ì˜ ë™ì‘ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("\n" + "="*60)
    print("ìƒí’ˆëª… ì •ê·œí™” í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    test_cases = [
        "ëŒ€í˜• ì‚¬ë¬´ìš©   ì§‘ê²Œí´ë¦½",  # ì—¬ëŸ¬ ê³µë°±
        " ëŒí”„ë¡œìŠ¤ ì•„íŠ¸ì½œë¼ ìê°œ ëª…í•¨ì¼€ì´ìŠ¤ ",  # ì•ë’¤ ê³µë°±
        "Test\tProduct\n",  # íƒ­, ê°œí–‰ ë¬¸ì
        "Product    With    Multiple    Spaces",  # ì—¬ëŸ¬ ì—°ì† ê³µë°±
        "MixedCase Product Name",  # ëŒ€ì†Œë¬¸ì í˜¼í•©
    ]
    
    for i, original in enumerate(test_cases, 1):
        normalized = ''.join(original.split()).lower()
        print(f"{i}. ì›ë³¸: '{original}'")
        print(f"   ì •ê·œí™”: '{normalized}'")
        hash_value = hashlib.md5(normalized.encode('utf-8')).hexdigest()[:16]
        print(f"   í•´ì‹œ: {hash_value}")
        print()

def check_existing_files():
    """ê¸°ì¡´ íŒŒì¼ë“¤ì˜ í•´ì‹œ íŒ¨í„´ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    print("\n" + "="*60)
    print("ê¸°ì¡´ íŒŒì¼ í•´ì‹œ íŒ¨í„´ ë¶„ì„")
    print("="*60)
    
    image_dirs = [
        r"C:\RPA\Image\Main\kogift",
        r"C:\RPA\Image\Main\naver", 
        r"C:\RPA\Image\Main\haereum"
    ]
    
    for img_dir in image_dirs:
        platform = os.path.basename(img_dir)
        print(f"\nğŸ“ {platform.upper()} ë””ë ‰í† ë¦¬: {img_dir}")
        
        if not os.path.exists(img_dir):
            print(f"   âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            continue
            
        files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]
        print(f"   ğŸ“Š ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: {len(files)}ê°œ")
        
        # íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„
        hash_patterns = {}
        for file in files[:10]:  # ì²˜ìŒ 10ê°œë§Œ ë¶„ì„
            if '_' in file:
                parts = file.split('_')
                if len(parts) >= 3:
                    prefix = parts[0]
                    first_hash = parts[1] 
                    second_hash_with_ext = parts[2]
                    second_hash = second_hash_with_ext.split('.')[0]
                    
                    pattern = f"{len(first_hash)}ì+{len(second_hash)}ì"
                    if pattern not in hash_patterns:
                        hash_patterns[pattern] = []
                    hash_patterns[pattern].append(file)
        
        print(f"   ğŸ” í•´ì‹œ íŒ¨í„´:")
        for pattern, files_with_pattern in hash_patterns.items():
            print(f"      {pattern}: {len(files_with_pattern)}ê°œ íŒŒì¼")
            if files_with_pattern:
                print(f"         ì˜ˆì‹œ: {files_with_pattern[0]}")

if __name__ == "__main__":
    test_hash_consistency()
    test_normalize_function()
    check_existing_files()
    
    print("\n" + "="*60)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("="*60) 